{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 16: Reduce overfitting with Drpout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint-Neural-Network.ipynb  iris.data.2\t\t\t sonar.all-data\r\n",
      "Deep-learning-day1.ipynb\t model_plot.png\t\t\t Weights\r\n",
      "Deep-learning-projects.ipynb\t Models\r\n",
      "Dropout-Chapter16.ipynb\t\t pima-indians-diabetes.data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 86.50% (4.81%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv('sonar.all-data', header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# baseline\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # compile model\n",
    "    sgd = SGD(learning_rate=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=16, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print('Baseline: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Dropout with the visible layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 86.50% (4.81%)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv('sonar.all-data', header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# dropout in the input layer with weight constraint\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(60,)))\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu',W_constraint=maxnorm(3)))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # compile model\n",
    "    sgd = SGD(learning_rate=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=16, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print('Baseline: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Dropout on Hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 86.50% (4.81%)\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv('sonar.all-data', header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# dropout in hidden layers with weight constraint\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    sgd = SGD(learning_rate=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossenrtopy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=16, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print('Baseline: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 17: lift performance with learning rate schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-01 15:32:25--  http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76467 (75K) [application/x-httpd-php]\n",
      "Saving to: ‘ionosphere.data’\n",
      "\n",
      "ionosphere.data     100%[===================>]  74,67K  32,5KB/s    in 2,3s    \n",
      "\n",
      "2020-03-01 15:32:28 (32,5 KB/s) - ‘ionosphere.data’ saved [76467/76467]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding Learning rate schedulers\n",
    "# Set decay constant, lr and starting epoch\n",
    "decay = 0.001\n",
    "lr = 0.01\n",
    "epoch = 0\n",
    "# collect lr and epoch values\n",
    "lr_list = []\n",
    "epoch_list = []\n",
    "# set up while loop for learning rate update\n",
    "while epoch < 50:\n",
    "    lr = lr * (1/(1+decay*epoch))\n",
    "    epoch+=1\n",
    "    lr_list.append(lr)\n",
    "    epoch_list.append(epoch)\n",
    "    #print(lr)\n",
    "# Verfiy the length of the lists\n",
    "len(epoch_list), len(lr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, lr_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6813 - accuracy: 0.6468 - val_loss: 0.6380 - val_accuracy: 0.8621\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6370 - accuracy: 0.7319 - val_loss: 0.5292 - val_accuracy: 0.8276\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.5585 - accuracy: 0.8213 - val_loss: 0.4757 - val_accuracy: 0.8362\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.4680 - accuracy: 0.8383 - val_loss: 0.4419 - val_accuracy: 0.9224\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.3844 - accuracy: 0.8681 - val_loss: 0.2779 - val_accuracy: 0.9483\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.3162 - accuracy: 0.8851 - val_loss: 0.3921 - val_accuracy: 0.8879\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.2755 - accuracy: 0.9106 - val_loss: 0.2269 - val_accuracy: 0.9483\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.2405 - accuracy: 0.9106 - val_loss: 0.1437 - val_accuracy: 0.9569\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.2437 - accuracy: 0.9106 - val_loss: 0.2217 - val_accuracy: 0.9483\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.2028 - accuracy: 0.9191 - val_loss: 0.2543 - val_accuracy: 0.9224\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.1919 - accuracy: 0.9234 - val_loss: 0.1894 - val_accuracy: 0.9483\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.1726 - accuracy: 0.9404 - val_loss: 0.1133 - val_accuracy: 0.9655\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.1800 - accuracy: 0.9319 - val_loss: 0.1033 - val_accuracy: 0.9741\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.1664 - accuracy: 0.9362 - val_loss: 0.1692 - val_accuracy: 0.9569\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1431 - accuracy: 0.9489 - val_loss: 0.0981 - val_accuracy: 0.9828\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.1477 - accuracy: 0.9447 - val_loss: 0.1673 - val_accuracy: 0.9569\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.1463 - accuracy: 0.9532 - val_loss: 0.1516 - val_accuracy: 0.9655\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.1354 - accuracy: 0.9489 - val_loss: 0.1199 - val_accuracy: 0.9914\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.1283 - accuracy: 0.9489 - val_loss: 0.0919 - val_accuracy: 0.9914\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.1220 - accuracy: 0.9660 - val_loss: 0.1129 - val_accuracy: 0.9914\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.1159 - accuracy: 0.9617 - val_loss: 0.1043 - val_accuracy: 0.9914\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.1093 - accuracy: 0.9574 - val_loss: 0.1083 - val_accuracy: 0.9914\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.1098 - accuracy: 0.9617 - val_loss: 0.1061 - val_accuracy: 0.9914\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.1017 - accuracy: 0.9660 - val_loss: 0.0758 - val_accuracy: 0.9914\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.1114 - accuracy: 0.9617 - val_loss: 0.1081 - val_accuracy: 0.9914\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0963 - accuracy: 0.9617 - val_loss: 0.0859 - val_accuracy: 0.9914\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0953 - accuracy: 0.9702 - val_loss: 0.0887 - val_accuracy: 0.9914\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0947 - accuracy: 0.9745 - val_loss: 0.0895 - val_accuracy: 0.9914\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0855 - accuracy: 0.9787 - val_loss: 0.0873 - val_accuracy: 0.9914\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0875 - accuracy: 0.9745 - val_loss: 0.0885 - val_accuracy: 0.9914\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0852 - accuracy: 0.9787 - val_loss: 0.0835 - val_accuracy: 0.9914\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0816 - accuracy: 0.9830 - val_loss: 0.0855 - val_accuracy: 0.9914\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0771 - accuracy: 0.9830 - val_loss: 0.0866 - val_accuracy: 0.9914\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0803 - accuracy: 0.9787 - val_loss: 0.0960 - val_accuracy: 0.9914\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0754 - accuracy: 0.9830 - val_loss: 0.0737 - val_accuracy: 0.9828\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0759 - accuracy: 0.9830 - val_loss: 0.0783 - val_accuracy: 0.9914\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0708 - accuracy: 0.9830 - val_loss: 0.0855 - val_accuracy: 0.9914\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0717 - accuracy: 0.9787 - val_loss: 0.0715 - val_accuracy: 0.9914\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0750 - accuracy: 0.9787 - val_loss: 0.0851 - val_accuracy: 0.9914\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0698 - accuracy: 0.9830 - val_loss: 0.0726 - val_accuracy: 0.9914\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0657 - accuracy: 0.9787 - val_loss: 0.0821 - val_accuracy: 0.9914\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0667 - accuracy: 0.9787 - val_loss: 0.0852 - val_accuracy: 0.9914\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0665 - accuracy: 0.9830 - val_loss: 0.0746 - val_accuracy: 0.9914\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0661 - accuracy: 0.9787 - val_loss: 0.0676 - val_accuracy: 0.9828\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0622 - accuracy: 0.9830 - val_loss: 0.0911 - val_accuracy: 0.9914\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0686 - accuracy: 0.9830 - val_loss: 0.0694 - val_accuracy: 0.9914\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0664 - accuracy: 0.9872 - val_loss: 0.0604 - val_accuracy: 0.9828\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0628 - accuracy: 0.9872 - val_loss: 0.0799 - val_accuracy: 0.9914\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.0769 - val_accuracy: 0.9914\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0595 - accuracy: 0.9872 - val_loss: 0.0614 - val_accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc50f799da0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fox random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv('ionosphere.data', header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:34]\n",
    "Y = dataset[:,34]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(34, input_dim=34, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "# compile model\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X, encoded_Y, validation_split=0.33, epochs=epochs, batch_size=28, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop-based learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6809 - accuracy: 0.6511 - val_loss: 0.6252 - val_accuracy: 0.9224\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6256 - accuracy: 0.7277 - val_loss: 0.4824 - val_accuracy: 0.8793\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.5197 - accuracy: 0.8213 - val_loss: 0.4360 - val_accuracy: 0.9224\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.3965 - accuracy: 0.8511 - val_loss: 0.3715 - val_accuracy: 0.9138\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.3103 - accuracy: 0.8894 - val_loss: 0.1614 - val_accuracy: 0.9569\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.2578 - accuracy: 0.8979 - val_loss: 0.3832 - val_accuracy: 0.8276\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.2194 - accuracy: 0.9277 - val_loss: 0.1249 - val_accuracy: 0.9655\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.2290 - accuracy: 0.9064 - val_loss: 0.1687 - val_accuracy: 0.9741\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.2012 - accuracy: 0.9191 - val_loss: 0.1660 - val_accuracy: 0.9741\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.1750 - accuracy: 0.9362 - val_loss: 0.1359 - val_accuracy: 0.9828\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.1506 - accuracy: 0.9532 - val_loss: 0.1551 - val_accuracy: 0.9741\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.1454 - accuracy: 0.9532 - val_loss: 0.0962 - val_accuracy: 0.9741\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.1474 - accuracy: 0.9489 - val_loss: 0.1201 - val_accuracy: 0.9741\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.1251 - accuracy: 0.9532 - val_loss: 0.1060 - val_accuracy: 0.9828\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1199 - accuracy: 0.9574 - val_loss: 0.1008 - val_accuracy: 0.9914\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.1242 - accuracy: 0.9617 - val_loss: 0.0965 - val_accuracy: 0.9914\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.1114 - accuracy: 0.9617 - val_loss: 0.1305 - val_accuracy: 0.9828\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.1076 - accuracy: 0.9660 - val_loss: 0.0932 - val_accuracy: 0.9828\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.1033 - accuracy: 0.9660 - val_loss: 0.1051 - val_accuracy: 0.9828\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0999 - accuracy: 0.9745 - val_loss: 0.0886 - val_accuracy: 0.9914\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0985 - accuracy: 0.9745 - val_loss: 0.0922 - val_accuracy: 0.9914\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0954 - accuracy: 0.9745 - val_loss: 0.0958 - val_accuracy: 0.9914\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0939 - accuracy: 0.9787 - val_loss: 0.0894 - val_accuracy: 0.9914\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0919 - accuracy: 0.9787 - val_loss: 0.0950 - val_accuracy: 0.9914\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0899 - accuracy: 0.9787 - val_loss: 0.0834 - val_accuracy: 0.9914\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0897 - accuracy: 0.9787 - val_loss: 0.0936 - val_accuracy: 0.9914\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0863 - accuracy: 0.9787 - val_loss: 0.0886 - val_accuracy: 0.9914\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0858 - accuracy: 0.9787 - val_loss: 0.0858 - val_accuracy: 0.9914\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0843 - accuracy: 0.9787 - val_loss: 0.0898 - val_accuracy: 0.9914\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0837 - accuracy: 0.9787 - val_loss: 0.0866 - val_accuracy: 0.9914\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0829 - accuracy: 0.9787 - val_loss: 0.0905 - val_accuracy: 0.9914\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0815 - accuracy: 0.9787 - val_loss: 0.0859 - val_accuracy: 0.9914\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0807 - accuracy: 0.9787 - val_loss: 0.0838 - val_accuracy: 0.9914\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0802 - accuracy: 0.9787 - val_loss: 0.0861 - val_accuracy: 0.9914\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0800 - accuracy: 0.9787 - val_loss: 0.0896 - val_accuracy: 0.9914\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0786 - accuracy: 0.9787 - val_loss: 0.0853 - val_accuracy: 0.9914\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0782 - accuracy: 0.9787 - val_loss: 0.0829 - val_accuracy: 0.9914\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0781 - accuracy: 0.9787 - val_loss: 0.0844 - val_accuracy: 0.9914\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0774 - accuracy: 0.9787 - val_loss: 0.0801 - val_accuracy: 0.9914\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0771 - accuracy: 0.9787 - val_loss: 0.0805 - val_accuracy: 0.9914\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0763 - accuracy: 0.9787 - val_loss: 0.0851 - val_accuracy: 0.9914\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0762 - accuracy: 0.9787 - val_loss: 0.0836 - val_accuracy: 0.9914\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0760 - accuracy: 0.9787 - val_loss: 0.0821 - val_accuracy: 0.9914\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.0818 - val_accuracy: 0.9914\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.0792 - val_accuracy: 0.9914\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0753 - accuracy: 0.9787 - val_loss: 0.0797 - val_accuracy: 0.9914\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0755 - accuracy: 0.9830 - val_loss: 0.0839 - val_accuracy: 0.9914\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0747 - accuracy: 0.9830 - val_loss: 0.0842 - val_accuracy: 0.9914\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0744 - accuracy: 0.9830 - val_loss: 0.0815 - val_accuracy: 0.9914\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0742 - accuracy: 0.9830 - val_loss: 0.0830 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc50f16ab70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor(1+epoch)/epochs_drop)\n",
    "    return lrate\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "dataframe = pd.read_csv('ionosphere.data', header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:34]\n",
    "Y = dataset[:,34]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(34, input_dim=34, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "# compile model\n",
    "sgd = SGD(learning_rate=0.0, momentum=0.9, decay=0.0, nesterov=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "# fit the model\n",
    "model.fit(X, encoded_Y, validation_split=0.33, epochs=50, batch_size=28,callbacks=callbacks_list,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
