{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements\n",
    "Scipy >= 0.17.0\n",
    "Numpy >= 1.11.0\n",
    "Matplotlib >= 1.5.1\n",
    "Panadas >= 0.18.0\n",
    "Scilit-learn >= 0.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy == 1.3.1\n",
      "pandas == 0.25.1\n",
      "numpy == 1.17.2\n",
      "scikit-learn ==0.21.3\n",
      "matplotlib == 3.1.1\n"
     ]
    }
   ],
   "source": [
    "print('scipy == {}'.format(sc.__version__))\n",
    "print('pandas == {}'.format(pd.__version__))\n",
    "print('numpy == {}'.format(np.__version__))\n",
    "print('scikit-learn =={}'.format(sk.__version__))\n",
    "print('matplotlib == {}'.format(mpl.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 18.1 from /usr/lib/python3/dist-packages/pip (python 3.7)\r\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "!pip3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Theano\n",
    "!pip install Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of Theano libarary\n",
    "import theano\n",
    "from theano import tensor\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tensor.dscalar()\n",
    "b = tensor.dscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{add,no_inplace}.0\n"
     ]
    }
   ],
   "source": [
    "# create a simple symbolic expression\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the expression into a callable object that takes (a,b) and computes c\n",
    "f = theano.function([a,b], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# bind 1.5 to 'a', '2.5' to b, and evaluate 'c'\n",
    "result = f(1.5, 2.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ahmed/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow : is an open source library for fast numerical computing, created and maintained by Google\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.3MB 19kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow==1.14.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/bc/7993faa8084b5a5dbabb07a197ae1b7590da4752dc80455d878573553e2f/wrapt-1.12.0.tar.gz\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.24.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/lib/python3/dist-packages (from tensorflow==1.14.0) (1.16.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==1.14.0) (0.32.3)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 1.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 388kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: h5py in /usr/lib/python3/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ahmed/.local/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/72/1c1498c1e908e0562b1e1cd30012580baa7d33b5b0ffdbeb5fde2462cc71/setuptools-45.2.0-py3-none-any.whl (584kB)\n",
      "\u001b[K    100% |████████████████████████████████| 593kB 737kB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ahmed/.cache/pip/wheels/54/f9/95/099544e9f879f719b14cf567fabb5aa7984263df0f025f3eef\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt, tensorflow-estimator, setuptools, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow 2.0.0a0\n",
      "    Uninstalling tensorflow-2.0.0a0:\n",
      "      Successfully uninstalled tensorflow-2.0.0a0\n",
      "Successfully installed setuptools-45.2.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 wrapt-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Eample of TensorFlow library\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "# create a simple symbolic expression using the add function \n",
    "add = tf.add(a, b)\n",
    "# bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c'\n",
    "sess = tf.Session()\n",
    "binding = {a: 1.5, b: 2.5}\n",
    "c = sess.run(add, feed_dict = binding)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras : is a minimalist python library for deep learning that can run on top of Theano or TensorFlow.\n",
    "#developed to make deep learning models as fast and easy as possible for research and development\n",
    "import keras \n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-26 19:32:15--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.172.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.172.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23278 (23K) [text/plain]\n",
      "Saving to: ‘pima-indians-diabetes.data.csv’\n",
      "\n",
      "pima-indians-diabet 100%[===================>]  22,73K  --.-KB/s    in 0,08s   \n",
      "\n",
      "2020-02-26 19:32:16 (290 KB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep-learning-day1.ipynb  pima-indians-diabetes.data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of trainable parameters:\n",
    "    = connections between layers + bias in every layer\n",
    "    = (8 * 12 + 12 * 8 + 8 * 1) + (12 + 8 + 1)\n",
    "    = 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pydot\n",
    "conda install -c anaconda pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGVCAIAAACEq5oKAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1gT19Yw8J0E5CagGAUsqPAVakG8nHKXFjgKFkSKBUSpNl4IFy9V0Iq16KmFFtAqlCMX5dTeQBFBuRzrU4qgVhFrFcGKWivP0YOgEoUIREOA/f2x33feFCSEkGQGun5/+IQ9kz1rJrKY2dmzhoUxRgAAwDBsugMAAICXgNwEAGAiyE0AACaC3AQAYCIN6R8uXry4b98+ukIBAPyVubi4xMTEUD/+6bzpv//9b0FBgdpDAuAlCgoKGhsb6Y5CJaqrq6urq+mOglmqq6svXrwo3aLRf6Vjx46pKx4ABsRisaKjo5csWUJ3IMoXHByM4Bftz8gxkQbjTQAAJoLcBABgIshNAAAmgtwEAGAiyE0AACaC3ARGj6KiInNz85s3b9IdiJKVlZWVlpbm5eXZ2tqyWCw3N7fu7m5q6dOnT7dt26avr6+joxMTEyMQCNQc3rFjx/h8/kcffbRs2bKdO3dKJBKEUE1NTWpq6nBKCbxkDgEAI5Sent6kSZO0tbVVt4nm5mZTU1PV9d9fZmYmQigqKgohNH/+fFNT0wsXLmzdupWaJm1kZJSUlCQWi58/f67+udP5+fm7d+++dOkSh8PBGC9cuDAuLi45OXnOnDltbW2xsbG7d+9WrGc4bwKjh5eX15UrVywsLFTUf2tr6/Lly1XU+UudPHmyoqKCJCaEEJfL1dDQQAilpKQUFhZKrzl16tRXX31VnbERBw8edHFx4XA4CCEWi+Xj41NcXEwWeXp66uvrp6enK9YznDcBIBeRSLR06dKGhga1bbG9vX3NmjUVFRXSjdbW1hYWFsXFxatXr545c6aVlRVp19HRkb7QU2eQ5eXlEolEU1MTIVRXV/fKK69QS2NiYiwtLX18fCwtLYfaM5w3gVGitbX1q6++8vLyKioqQghdu3btww8/tLS07OzsDAsL43K5jo6OJLPU19d//PHHNjY2TU1NAQEBRkZGjo6O5CaSI0eOGBgYmJubI4SEQmF8fDyHw3FxcUEInThx4ubNmwKBgM/nf/HFFwihCxcumJubnzp1SkV7lJ2draWlZWNjI93IZrNzcnJmzJjx7NmzwMDA58+fv/S9hYWF69ev37Jli4+PT1xcnFgsln1MEEIY46ysrKioKCcnJ29v7zt37sgTJJ/Pv3Xrlq+vr1AorK6uvnTpUkpKCrVUT0/P3t7+s88+U2T/sZSjR4/2aQGALgiho0ePyr9+fX19dHQ0QqigoABj3NzcPH/+fITQunXrbty4UVNTo6WltXTpUozxtm3bxo0bx+FwoqOjKysrCwsLuVyurq5uU1MTxtjb29vMzIzq1s7OztnZmbz28/ObNm0atejkyZM6Ojq5ublD3bWgoKCgoKBBV3NxcQkODu7TOHv2bIxxQ0PDhAkTEEI8Ho+0Z2Vl7d+/n7xOSUlxdXXt6urCGAsEAisrK3d3997eXhnHBGOcmJj4zTffYIy7u7ttbGxMTEw6Ozvl2Z1du3YhhKytrf38/FpbW/ssjY+PNzQ07O7ult1J/2MCuQkw1FBzE8b4zJkzVG7CGH/00UcIIYFAQH50c3OzsrIir0NDQzU1NclvL8aY3Nq2c+dOjHFAQIB0bnJ2dh4oN2GMB/2Veyl5clNPT4+mpmZkZGSfdpKbMMaVlZXkMurgwYNYKjc9evRIT0/vu+++o97y9ddfI4S+//57PPAxefDggbGxcU9PD2nfuXMnQigvL0/OPXJ1dWWxWGPHjj19+nSfRQcPHkQI1dXVye6h/zGBazowepBxYgoZoKUazczM2tvbyWtdXV0Oh0N+txFCAQEBWlpa169fH+oWySZUobW1VSKRjB8/fqAVPDw80tLSEEIbNmy4evUq1V5dXd3Z2TllyhSqxc/PDyFUWVmJBj4mVVVVEokkIiKCz+fz+fympqawsDAdHZ1B4+zu7l61atXKlSt//PFHLS0tX19faiycGDduHELo0aNHQ9h5hBCMhQOAENLQ0Jg8eTItY8kDIUmkp6dHxjqRkZF1dXWZmZnBwcF8Pl9fXx8hdO/ePYTQ06dPqdWoK1YZXd28eVNPTy87O3uocW7atOn+/fvk1OzcuXNeXl48Hu/+/fsGBgZkBTabjRDq7e0das9w3gQAQgiJRKLp06fTHcX/MTQ01NbWbmtr69OO/zybMS0tzcPDo6GhgRpvJlMo+n+fKHvvdHV1Gxsb+xTMamlpGTTOvLw88l0BQsjGxiYxMVEoFNbU1FArkCxpYmIyaFd9QG4CADU3N7e0tAQFBSGENDQ0Ojo6qBOWjo4O6m8+m83u6OiQfqMCpwNyYrFYrq6ufU52MMYikUi6RUNDo6CgwMLCggrMxcXFwMCAfFlJNDY2ikQif39/GZuzs7PDGMfGxlItd+/ezcjIGDROLpdLXSkjhOzt7RFCkyZNoloEAoGBgYGtre2gXfUBuQmMHs3NzUjqr71QKEQIUVdqjx8/lv7FFovFtbW15HVCQgKPx3N0dEQI2dnZtbW1JSYm/v777wkJCWKx+Pbt2+REYPLkyQKB4MqVK2fOnBGJROXl5ePHj1ddqdjQ0NCqqirpE6XGxsaHDx+Sm0IoEyZMKCkpGTt2LPVjcnLyhQsXTp8+TVrS0tJ4PJ6npyca+Jh4eXk5ODgcPnw4MDAwJycnIyMjIiJi3bp1CKG1a9e6ubn98ccfLw0yPDz8yJEj1DEvKyt78803X3vtNWqFqqqqwMBARQbmpAfG4Xs6wBxoiN/TnT59+q233kII2dvbl5WVlZeXT5s2jfxqPX78+LvvviO/vZ988kl3d3dYWNiYMWOio6ODg4PXrFkTHx/f29tL+hEKhYsWLRo7dqyzs/Ply5dXrly5fPnykpISjHFtba2ZmZm1tfWxY8cwxhUVFaampkVFRUPdNTnnEHR1dVlZWZH0hDE+fvy4u7s7QigoKOjnn3/us3JRUVF6err0j97e3uvXr9+xY8fevXvJ3sk+Jk+ePHnvvfcmTZo0ceLE999//8GDB6SrhQsXstns2NjYgeI8cODAggULNm/evHXr1g8++ODJkyfUIpFIZGRkdOvWLQWOCeQmwFBDzU1DEhYWpq2traLOByVnbsIYX7582d/fX9XxDOrcuXNJSUkKvDEuLm7Pnj3yrAlzCAAYSezt7UNDQ6VnWqtfe3t7aWkpdU+f/E6dOiWRSLZs2aLYdpWTm6QHwwBgvo6ODolEgodRwUNtQkJCbG1tS0pK6Aqgrq7u008/peYEyKm2tlYoFCYlJSm83eHmpgMHDri7u7/++uvD7EdZ2tra4uLiyORXeTCn4k95eXlYWBiLxWKxWAsWLMjNzVX1Fo8dO+bs7Ey2uHHjxmvXrql6iwyRmZn5008/9fT0hIeHnz9/nu5wBuft7S37WzaVmjt3rgJlZ2bNmrV06dLhbHe4uSksLKy3t1f2DDG1KS0tjYiI+Oyzz/p80SuDeir+yLPa/Pnz//Wvf02cOBEhdOjQoffee0/V8QQHB6empiKEZs+e/eWXX86ePVtFW2SaqKgoctNGdna2m5sb3eGAlxtubuJwOGZmZkoJZfgWLVo01ImtTKv4Q86cDQ0N1RMPuZ9AdZsDQGGjbSxcS0uL7hD+jwIVf1gsFvWvGuJR6eYAGA4Fc1NxcXF4eHhsbOyGDRukr1nwy0rAyK4ac+3atVWrViUnJ7/zzjteXl4y+lE6hlf8UUM8g3r06BGfz4+Pj+fz+YsXL37y5AlCqLi4WF9fn8VipaamdnV1IYQuXrxoamr6+eefowE+uwcPHiQlJc2YMePp06cLFiyYOnUq6QqAAUlPKJBzflNubq6Tk9Pz588xxi0tLVwu18TEhCx6aQkY2VVjrK2tz58/jzEWiURubm4y+pFnlsSLFy8QQuvXr5dnZQZW/CFlVTs6OtQTz61btxBCHh4eA8Xj4eEREhJCXs+aNWv58uXk9bZt2xBCly9fJj+KxWInJyfy+qWf3alTp6ZPn87hcP7xj38cPHjQ0dGRmto3EKTK+U30kn9+01+HEuZednZ2mpqaHj58mGpZvHgxyU0ySsAMVDWmq6uLxWJ9+eWXpP3EiROy+xnUkHITZl7FH+ncpIZ4Bs1Nnp6en3/+OXn93nvvzZw5k7z+73//q6GhERYWRn7897//HR8fj2V+dmvWrEEI3blzR8buS4Pc9JfS/5gMuUbKzz//3NzcbGdnR7VQQzxUCRhqEVUCpn/VGHJ7jqam5oIFCzZt2vTbb78lJSUFBATI7kfpBq34Q91GREvFHzXEIxspVv3ixYvc3NxffvkF/++EIDMzs+Dg4JycnMTERC6Xm5+f/49//APJ/Ow0NTU1NDSGVG8/JCQkJCREmfvDJDDM1we515oy5NxE/tKOGTOm/yLFSsAUFhby+fzs7OwTJ07k5+d7enoqXEpGnZhW8UdF8fT09OzevfvXX3/94IMPnJycyJAWER0dfeTIkYMHD27ZskUgEJBi9cr97DZt2kTV3xhNyDxvMp4AiP5z34ecm0hWunfvnrW1dZ9FVAkY6VkFLS0tZM7OQDQ0NHJzcxcuXLh58+a333772rVrivWjfkyr+KPceO7cufPKK68sXrx40qRJ5HFD//rXv6RXcHBwmDt3bnp6+vTp0xctWkQalfvZubi4LFmyZBg7wVDkAnxU7prCyDGRNuTv6WbOnIkQIiNTBDX3UoESMGKxmJQTDg0Nra6uxhhXVlYqXEpGnVRU8YdcNOGh30uhWDwDbQhjHBkZWVNTU1ZW5uHhQRr73+SxefPmpqamzZs3BwcHk5YR8dmBEWHI501z58719PT85ptv3njjDR6Pd+PGjfPnz7e0tBw5csTf35+UgHnx4sXixYufPXt2/PjxvLw8JLOSzqFDh6KiojgczuTJkw0NDf/2t785OTkN1M+gOjs70WCVTKUpUPFn1qxZqF/Fn4KCgsTExCVLluTn54vF4v/+9781NTVz5syhKv60t7c7OjqSWjZfffVVn0tryrNnz0gYpHiFquMh/fcprigUCj/44IPx48eTca5vv/3W0dHx8uXLN27cePToUV1dnbGxsbGxMULI399/ypQps2bNIs/8QFJlgPp/diRdtrW1kQmfAAxCemBczjkEQqFw1apVxsbGU6ZM+eSTT8LDw1etWlVeXt7T0/PSEjAyqsZ0dnY6ODgsWLAgKSkpPDw8OzubbGKgUjKylZWVkUnPlpaWBw4cIF+oy8Coij+VlZVr164lH4qPj09eXp6q4ykqKqLu2Jg1a5a3t7eXl9f06dPJZfuBAwcwxpGRkfr6+s7OzuXl5T/88AOXyw0KCqK+RsQYR0REkF2jvPSzO3jwILmsW7FixdWrV+X5NBF8T/dXAvWbFEdvxZ/+mBBPb2+vvb09memmdJCb/lKUMIeARjLGUw8dOkQNxyrlXUAep0+f/vvf/67SO6XBX9ZIyk3yPPVBWe/qj6r4w5BpKTTGc/78+YiICFtb299+++3cuXNq3vpfUFlZmVgs7uzsjI+Pr6+vnzt37pkzZ6hZb0+fPt29e3d6enp3d3dUVNT27du5XK46wzt27FhZWRmXy/3Pf/5jZWW1Y8cOTU3Nmpqas2fPbty4UfH/n9InUXBNN5CMjAwy3BsWFta/VPNfLZ76+npLS8v/9//+37lz51S3FaTKa7pBxyJV2smQrukyMjIyMjLI65aWFpKSoqOj+6y2adOmiIgIxeIZjqNHj77xxhvkbofe3l4fH5+tW7eSRRUVFR9++KGc/UBNXgUxreIPvfG8/vrrd+/e/eOPP9588001b1ophlq4RnWdDOrkyZMVFRVUPVwul0tyU0pKCpl0Rpk6deqQ5twry8GDB11cXMgNDCwWy8fHh3qur6enp76+fnp6umI9j6RrOgCGT4HCNSrqZFDt7e1r1qwhtw1RrK2tLSwsiouLV69ePXPmTCsrK9Kuo6NDy10K7e3t5eXlEomE3D5VV1f3yiuvUEtjYmIsLS19fHzIbQNDAudNYGQrLCxcv379li1bfHx84uLixGIxGkqhGFqq38gpOztbS0vLxsZGupHNZufk5MyYMePZs2eBgYHPnz+X/7DIrlaEFSpMxOfzb9265evrKxQKq6urL126JH33iZ6enr29PfXM4aHpc+mIYLwJMAOSY7wpJSXF1dWVFGMQCARWVlbu7u5knpechWLUVv1GmpzjTS4uLsHBwX0aZ8+ejTFuaGggA448Ho+0Z2Vl7d+/X/ZhkV2tSOHCRLt27UIIWVtb+/n5tba29lkaHx9vaGgou/wGhvEmMJo8fvw4Li4uMjKSXE1MmDBh+/btZ8+eJY+B0NXVlV5ZT0/vpZ0kJib6+vqy2ezk5GQPD4933303MzNTJBJlZWXJ3wlCyNfXt729PTQ0dPj7RfT29v7666/UhPs+LCwsCgoKNDU1v/322z53Vss4LCYmJg4ODgihXbt22djYzJ4928HB4cqVKwihpqam1NTUFStWIIQ4HE5QUNDDhw9LS0vlCXXnzp2urq537tw5c+bM1atX+yw1NjYWCoX19fVDPQKQm8BIVV1d3dnZOWXKFKrFz88PIVRZWTmkfmipfjOo1tZWiUQyfvz4gVbw8PBIS0tDCG3YsEE6I8g+LP2r7pAHuFHFbfh8Pp/Pb2pqkrMwUXd396pVq1auXPnjjz9qaWn5+vpSY+EEuUXp0aNHQ9h5hBCMhYOR6969ewihp0+fUi3U5dhwumVI9RuSRGTfGRoZGVlXV5eZmRkcHMzn8/X19ZGih0Xh4jabNm26f//+119/jRA6d+6cl5cXj8e7f/8+9Tw7NpuNBrvF/aXgvAmMVOTpOP2/LBt+oRgmVL8xNDTU1tbucxs26lc6Ii0tzcPDo6GhgRpvVuywUMVtpBvlmbecl5dH1diysbFJTEwUCoU1NTXUCiRLmpiYDNpVH5CbwEjl4uJiYGBAnkNBNDY2ikQi8pjJIRWukaai6jdDxWKxXF1d+5zsYIylC1GQCAsKCiwsLKhgZB+WgShc3IbL5Uo/1tve3h4hNGnSJKpFIBAYGBjY2toO2lUfkJvASDVhwoTk5OQLFy6cPn2atKSlpfF4PE9PT4SQnZ1dW1tbYmLi77//npCQIBaLb9++Tf6eU4Vizpw5Q37VSbUZ0kmfajNydlJeXj5+/PiCggIl7mBoaGhVVZX0iVJjY+PDhw8lEkmf41BSUkJqVAx6WAaqukMVtwkMDMzJycnIyIiIiFi3bh1CaO3atW5ublQx6D7Cw8OPHDlCnWGVlZW9+eabr732GrUCqQukyGCc9Jd2MIcAMAeS756VoqIib2/v9evX79ixY+/evQoUrlF19Zv+5JxD0NXVZWVlRdITxvj48ePu7u4IoaCgoP43KhUVFaWnp8s+LLKr7gxUmGjhwoVsNjs2NnagOA8cOLBgwYLNmzdv3br1gw8+ePLkCbVIJBIZGRndunVLgWMCuQkwlJy5afjUX21G/vvpLl++7O/vr+p4BnXu3LmkpCQF3hgXF7dnzx551oT5TQCMJPb29qGhof3r/KtTe3t7aWkpdU+f/E6dOiWRSLZs2aLYdiE3gb86qtoM3YG8XEhIiK2tbUlJCV0B1NXVffrpp9ScADnV1tYKhcKkpCSFtwvzm8BfWmZm5k8//dTT0xMeHs7j8ZhQZKI/b29vGrc+d+5cBd41a9YsUsleYZCbwF9aVFSUAlcrQA3gmg4AwESQmwAATAS5CQDARJCbAABM9JKx8Pz8fPXHAUB/Fy9epDsElSC31MIvmrTGxkYzM7M/NUlPxCTzwgEAQP36zAtnMXbKGRhxWCzW0aNHlyxZQncgYDSA8SYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE7EwxnTHAEaqiIiI27dvUz9evXrVwsJi/Pjx5EcOh/Ptt9+amZnRFB0Y2TToDgCMYMbGxgcPHpRuqauro15bWlpCYgIKg2s6oLjQ0NCBFo0ZM2blypVqjAWMNnBNB4ZlxowZ9fX1L/1fdPv2bWtra/WHBEYHOG8Cw/L+++9zOJw+jSwWa9asWZCYwHBAbgLDsmzZsp6enj6NHA6Hx+PREg8YNeCaDgyXq6vrpUuXent7qRYWi/Xf//73lVdeoTEqMNLBeRMYrhUrVrBYLOpHNpvt5uYGiQkME+QmMFzBwcHSP7JYrPfff5+uYMCoAbkJDBeXy503bx41Is5isRYvXkxvSGAUgNwElGD58uVk4JLD4SxYsGDChAl0RwRGPMhNQAnefffdMWPGIIQwxsuXL6c7HDAaQG4CSqCnp+fn54cQGjNmzKJFi+gOB4wGkJuAcrz33nsIocWLF+vp6dEdCxgVME2OHj1K964DAAYRFBREV4qguQ4BZCimuXjxYmpqqmKfS05OztKlSzU0mFvcIiQkZNOmTS4uLnQHMjKkpKTQuHWa/xstWbKE3gBAf6mpqYp9Lv7+/tra2kqPR4lCQkJcXFzgf52cjh07RuPWYbwJKA3DExMYWSA3AQCYCHITAICJIDcBAJgIchMAgIkgNwElKCoqMjc3v3nzJt2BqFBZWVlpaWleXp6trS2LxXJzc+vu7qaWPn36dNu2bfr6+jo6OjExMQKBQM3hHTt2jM/nf/TRR8uWLdu5c6dEIkEI1dTUpKam4pFZo425U1HACKKnpzdp0iSVfk/X3Nxsamqquv5ly8zMRAhFRUUhhObPn29qanrhwoWtW7fu27ePrGBkZJSUlCQWi58/f041qk1+fv7u3bsvXbrE4XAwxgsXLoyLi0tOTp4zZ05bW1tsbOzu3bvVHNLwwXkTUAIvL68rV65YWFioqP/W1lYabyE+efJkRUUFSUwIIS6XS+aXpqSkFBYWSq85derUV199Vf0RHjx40MXFhZSpYbFYPj4+xcXFZJGnp6e+vn56err6oxomOG8CTCcSiZYuXdrQ0EDL1tvb29esWVNRUSHdaG1tbWFhUVxcvHr16pkzZ1pZWZF2HR0d6Qs9dQZZXl4ukUg0NTURQnV1ddJ1R2NiYiwtLX18fCwtLdUfm8LgvAkMV2tr61dffeXl5VVUVIQQunbt2ocffmhpadnZ2RkWFsblch0dHUlmqa+v//jjj21sbJqamgICAoyMjBwdHaurqxFCR44cMTAwMDc3RwgJhcL4+HgOh0NuLjlx4sTNmzcFAgGfz//iiy8QQhcuXDA3Nz916pQa9i47O1tLS8vGxka6kc1m5+TkzJgx49mzZ4GBgc+fP3/pewsLC9evX79lyxYfH5+4uDixWIxkHh+EEMY4KysrKirKycnJ29v7zp078gTJ5/Nv3brl6+srFAqrq6svXbokfbuJnp6evb39Z599puAhoAtdN/KRO7bo2joYiAKfS319fXR0NEKooKAAY9zc3Dx//nyE0Lp1627cuFFTU6OlpbV06VKM8bZt28aNG8fhcKKjoysrKwsLC7lcrq6ublNTE8bY29vbzMyM6tbOzs7Z2Zm89vPzmzZtGrXo5MmTOjo6ubm5Q907hNDRo0eH9BYXF5fg4OA+jbNnz8YYNzQ0kCp6PB6PtGdlZe3fv5+8TklJcXV17erqwhgLBAIrKyt3d/fe3l4ZxwdjnJiY+M0332CMu7u7bWxsTExMOjs75Ylz165dCCFra2s/P7/W1tY+S+Pj4w0NDbu7u4e070FBQTTe6wu5CfyJYp/LmTNnqNyEMf7oo48QQgKBgPzo5uZmZWVFXoeGhmpqapLfWIwxuWNr586dGOOAgADp3OTs7DxQbsIYD/XXjBhqburp6dHU1IyMjOzTTnITxriyspJcRh08eBBL5aZHjx7p6el999131Fu+/vprhND333+PBz4+Dx48MDY27unpIe07d+5ECOXl5ckZraurK4vFGjt27OnTp/ssIo+Gr6urk3/fMd25Ca7pgBL0qT1ABmWpRjMzs/b2dvJaV1eXw+GQ32eEUEBAgJaW1vXr14e6xf4P7FSF1tZWiUQyfvz4gVbw8PBIS0tDCG3YsOHq1atUe3V1dWdn55QpU6gWUnuvsrISDXx8qqqqJBJJREQEn8/n8/lNTU1hYWE6OjqDxtnd3b1q1aqVK1f++OOPWlpavr6+1Fg4MW7cOITQo0ePhrDzdIOxcEAnDQ2NyZMn0zJ+LA+SRPo/HFRaZGRkXV1dZmZmcHAwn8/X19dHCN27dw8h9PTpU2o16upVRlc3b97U09PLzs4eapybNm26f/8+OTU7d+6cl5cXj8e7f/++gYEBWYHNZiOEpJ8hyHxw3gRoJhKJpk+fTncUL2doaKitrd3W1tanHf95NmNaWpqHh0dDQwM13kymU/T/blH2nurq6jY2NjY2Nko3trS0DBpnXl4eVZTKxsYmMTFRKBTW1NRQK5AsaWJiMmhXzAG5CdCpubm5paUlKCgIIaShodHR0UGdpHR0dFB/59lsdkdHh/Qb1XMKwGKxXF1d+5zsYIxFIpF0i4aGRkFBgYWFBRWki4uLgYEB+eKSaGxsFIlE/v7+MjZnZ2eHMY6NjaVa7t69m5GRMWicXC6XumpGCNnb2yOEJk2aRLUIBAIDAwNbW9tBu2IOyE1ACZqbm5HUX3ihUIgQoq7UHj9+LP3LLBaLa2tryeuEhAQej+fo6IgQsrOza2trS0xM/P333xMSEsRi8e3bt8kf/8mTJwsEgitXrpw5c0YkEpWXl48fP76goEANuxYaGlpVVSV9otTY2Pjw4UNyUwhlwoQJJSUlY8eOpX5MTk6+cOHC6dOnSUtaWhqPx/P09EQDHwy7GgoAACAASURBVB8vLy8HB4fDhw8HBgbm5ORkZGRERESsW7cOIbR27Vo3N7c//vjjpUGGh4cfOXKEOv5lZWVvvvnma6+9Rq1QVVUVGBionkE6paFrEB6+p2MmBT6X06dPv/XWWwghe3v7srKy8vLyadOmIYTWrl37+PHj7777jvzGfvLJJ93d3WFhYWPGjImOjg4ODl6zZk18fHxvby/pRygULlq0aOzYsc7OzpcvX165cuXy5ctLSkowxrW1tWZmZtbW1seOHcMYV1RUmJqaFhUVDXXv0NDnEHR1dVlZWZH0hDE+fvy4u7s7QigoKOjnn3/us3JRUVF6err0j97e3uvXr9+xY8fevXvJnso+Pk+ePHnvvfcmTZo0ceLE999//8GDB6SrhQsXstns2NjYgeI8cODAggULNm/evHXr1g8++ODJkyfUIpFIZGRkdOvWrSHtOKb7ezrITeBPVP25hIWFaWtrq65/2RTITRjjy5cv+/v7qyKeITl37lxSUpICb4yLi9uzZ48Cb4Q5BEMjfV0NgBrY29uHhobSW9i/vb29tLSUuqdPfqdOnZJIJFu2bFFFVCo1knLTgQMH3N3dX3/9dboD+R9tbW1xcXFkHp08jh8/7unpyWKxyAirm5vbnDlznJ2dY2Nj7969q9JQmaOjo0MikeCRVrUjJCTE1ta2pKSErgDq6uo+/fRTak6AnGpra4VCYVJSkoqiUi26TtgUuHbo7u52c3MzMTFRUUhDUlJSQh7XsX79evnfRb4enjp1KtXyyy+/vP322xwOZ/v27dSEYBqp9JouIyOD3OQRFhbWf7BGDZBC13R/WXBNJy8Oh2NmZkZ3FP9j0aJFCsyRI8+8lZ7p6+DgcPLkyZCQkM8//zw5OVmZITJPVFQUuVEjOzvbzc2N7nAAo42k3MQ0WlpaQ30Li8Xq38hmszMyMiZNmpSQkHD//n1lhAbAiDcCclNxcXF4eHhsbOyGDRvIPBoCv6yahOwCFNeuXVu1alVycvI777zj5eUlox+FKVa+w9DQcMmSJSKRKD8/n7G7BoBa0XUxKee4Rm5urpOT0/PnzzHGLS0tXC6XGm96aTUJ2QUorK2tz58/jzEWiURubm4y+pFnF168eIH6jTfJLt9B7n6YPn16/0U5OTkIoVWrVtG7a6N7bgeC8aahgPlNA+rs7DQ1NT18+DDVsnjxYpKbZFSTGKgARVdXF4vF+vLLL0n7iRMnZPczqJfmJiyzfIeM3PTjjz8ihObNm0fvrkFuAhR6cxOj6xD8/PPPzc3NdnZ2VAs1xENVk6AWUdUk+hegIDP9NTU1FyxYsGnTpt9++y0pKSkgIEB2PwpT7M4Ach+DtbU1E3aNXFqOShcvXqQ7hBGjsbGRxm+fGJ2bbt26hRAaM2ZM/0WKVZMoLCzk8/nZ2dknTpzIz8/39PRUuCqF0pEHKM2aNYsJuxYSEqLAu0aE1NTU1NRUuqMYMcht2LRg9Fg4yUqkFE4filWT0NDQyM3Nzc3N1dDQePvtt2/evKlwVQrlwhgXFBRoamq+/fbbTNg1uk7jVQ3BNd1Q0JiYEMNz08yZMxFCZASE6O3tJTU0FKgmIRaLSWXS0NDQ6upqjHFlZaXCVSlkkFG+Aw8wH3rv3r3Xr1+PjY2dOnUqk3cNALVh9DXd3LlzPT09v/nmmzfeeIPH4924ceP8+fMtLS1Hjhzx9/cn1SRevHixePHiZ8+eHT9+PC8vD8ks0HHo0KGoqCgOhzN58mRDQ8O//e1vTk5OA/UzqM7OTtSvKGJ5eXlgYOBXX3310r85pL6PdMGQe/fu7d27d//+/Rs3biTl6KlCGTTuGgD0o+t0Uc7vg4RC4apVq4yNjadMmfLJJ5+Eh4evWrWqvLy8p6fnpdUkZBSg6OzsdHBwWLBgQVJSUnh4eHZ2NtnEQFUpZCsrKyNPc7S0tDxw4AB5UgiWWb6jqKiIlO9BCLm5uc2bN8/X19fHxycmJqa2tlZ6TRp3Db6nAxR6v6djYZruuszPzw8JCaFr62Ago/tzYbFYR48eJTdCgkEFBwcjhMizcNSP0dd0NJo4ceJAiw4dOrRo0SJ1BgPAXxDkppdT/1d1AABpjP6eDgAalZWVlZaW5uXl2draslgsNzc36WdVPX36dNu2bfr6+jo6OjExMQKBQP0RDlRB7PDhw/b29gYGBk5OTj/88ANprKmpSU1NHUFX65CbgFpJ361NbyeyZWZm3r17d9GiRUuXLj179qyGhsaFCxe2bt1KrWBkZJSUlBQWFsbj8fbt28flclUdUh+lpaURERGfffZZnyfQpKSk5OTkrFixYvXq1b/99pufn195eTlCaM6cObNmzZKeU8JwkJuA+rS2tpIvN2nvRLaTJ09WVFRQBXC5XC65TyglJaWwsFB6zalTp7766qsqDWYgL60g1tHR8e9///vkyZMbN25MTU0tLy9nsVh79uwhSz09PfX19dPT09UerCJgvAmoiUgkWrp0af/HSaq/E9na29vXrFlTUVEh3WhtbW1hYVFcXLx69eqZM2daWVmRdh0dHRofSty/gtilS5eSkpKoMmEuLi5z5syRfnJUTEyMpaWlj4+PpaWl+gJVCJw3AQUVFhauX79+y5YtPj4+cXFxYrEYIXTkyBEDAwNzc3OEkFAojI+P53A45JGzJ06cuHnzpkAg4PP5X3zxRX19/ccff2xjY9PU1BQQEGBkZOTo6FhdXT2kTpCiBbNkyM7O1tLSsrGxkW5ks9k5OTkzZsx49uxZYGDg8+fP5T8msgtvYaXW2Jo3b56Dg4N0i6GhIZkWR+jp6dnb21PPH2Y0uiZWje45fiOXnJ9LSkqKq6trV1cXxlggEFhZWbm7u5Pnr3l7e5uZmVFr2tnZOTs7k9d+fn7Tpk0jr7dt2zZu3DgOhxMdHV1ZWVlYWMjlcnV1dcksVjk7wYMVzOoDyTH30sXFJTg4uE/j7NmzMcYNDQ2k3jmPxyPtWVlZ+/fvl31MZBfeUrh8GB64Sg+lu7t74sSJhw4dkm6Mj483NDSUUcmHAvXCwQjz+PHjuLi4yMhITU1NhNCECRO2b99+9uzZ3NxchJCurq70yqREen+JiYm+vr5sNjs5OdnDw+Pdd9/NzMwUiURZWVnyd4IQ8vX1bW9vDw0NHf5+IYR6e3t//fVXkoD6s7CwILdkf/vtt33GemQcExMTE3Ius2vXLhsbm9mzZzs4OFy5cgUh1NTUlJqaumLFCoQQh8MJCgp6+PBhaWmpUvYFIVRcXDx79uyVK1dKNxobGwuFwvr6emVtRUUgN4Ehq66u7uzsnDJlCtXi5+eHEKqsrBxSP7q6uhwOh/wyI4QCAgK0tLSuX78+1HiU+Cjt1tZWiUQyfvz4gVbw8PBIS0tDCG3YsOHq1atUu+xj0r/wFnnMIlVji8/n8/n8pqam4ZcPk96XhISE77//vk+V+nHjxiGEHj16pJStqA6MhYMhI1Vrnj59SrVQl2PD6VZDQ2Py5Mk0Di2j/00ife7f7iMyMrKuri4zMzM4OJjP5+vr6yNFj4lKy4dFR0enpqYaGxv3aWez2UhmtQyGgPMmMGQWFhYIof5flk2fPn2YPYtEouF3MhyGhoba2tqkdLI0/Ocpi2lpaR4eHg0NDdSgsmLHRHXlw9LT0wMCAt56663+i0gCNTExGf5WVApyExgyFxcXAwODoqIiqqWxsVEkEvn7+yOENDQ0Ojo6qFOPjo4O6k80m83uM1FQWnNzc0tLC6ktM6ROlHgKQB653OdkB2MsXdaGhFdQUGBhYUFFIvuYDERFNbYOHz6so6NDSjMTZPolIRAIDAwMbG1th7kVVYPcBIZswoQJycnJFy5cOH36NGlJS0vj8XikAoydnV1bW1tiYuLvv/+ekJAgFotv375dU1ODEJo8ebJAILhy5cqZM2fIb7tYLK6trSWdJCQk8Hg8R0fHIXVSXl4+fvz4goICZe1daGhoVVWV9IlSY2Pjw4cPJRJJn4NQUlJCytQMekwGKrxF1eoKDAzMycnJyMiIiIhYt24dQmjt2rVubm7SU5P6e2kFsR9++OGf//ynRCI5cODAgQMHsrKy1q5dS8pbE1VVVYGBgUocpFMVur4ghDkEzCT/51JUVOTt7b1+/fodO3bs3buXTCDAGAuFwkWLFo0dO9bZ2fny5csrV65cvnx5SUkJxri2ttbMzMza2vrYsWMY47CwsDFjxkRHRwcHB69ZsyY+Pl6BTmQUzOoPyTGHoKury8rKiqQnjPHx48fd3d0RQkFBQf2fk15UVJSeni77mMgovNXd3T1Qja2FCxey2ezY2NiB4nxpBbFffvml/1C6lpbWkydPyLtEIpGRkdGtW7fkOVzwDCjAIOr8XMLCwrS1tdWzLUKe3IQxvnz5sr+/vxrike3cuXNJSUnK7TMuLm7Pnj1yrgzzmwBgFnt7+9DQ0JSUFBpjaG9vLy0tpe7pU4pTp05JJJItW7YosU/VgdwEaNPR0SGRSDAjq3aEhITY2tqWlJTQFUBdXd2nn35qYGCgrA5ra2uFQmFSUpKyOlQ1mN8E6JGZmfnTTz/19PSEh4fzeDw3Nze6I+rL29ubxq3PnTtXuR3OmjVr1qxZyu1TpSA3AXpERUUp94IFjDJwTQcAYCLITQAAJoLcBABgIshNAAAmonksnDycDzAHue90FH8uKSkpdD0McsSprq52dnama+u0Pdf34sWL+/bto2XTQEVOnTo1Z84c5t/gDuTn4uISExNDy6Zpy01g9IEnegMlgvEmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEeQmAAATQW4CADCRBt0BgBGsra0NYyzd0tnZ2draSv04duxYTU1NtccFRgNWn/9bAMjv73//e2Vl5UBLORzOgwcPjI2N1RkSGDXgmg4obtmyZSwW66WL2Gz2W2+9BYkJKAxyE1BcUFCQhsbLhwVYLNb777+v5njAaAK5CShu/Pjx3t7eHA6n/yI2m7148WL1hwRGDchNYFiWL1/e29vbp1FDQ2PhwoWGhoa0hARGB8hNYFj8/f21tLT6NPb09CxfvpyWeMCoAbkJDIuuru7ixYv7TBTQ0dHx9fWlKyQwOkBuAsMVGhoqkUioHzU1NYOCgnR0dGgMCYwCkJvAcC1YsEB6aEkikYSGhtIYDxgdIDeB4dLU1Fy6dOmYMWPIj+PGjZs3bx69IYFRAHITUIJly5Z1dXUhhDQ1NZcvXz7QpCcA5Af3rAAl6O3tnTx58qNHjxBC58+fnzt3Lt0RgREPzpuAErDZ7BUrViCETE1NXV1d6Q4HjAa0nXs3NjZWVVXRtXWgdFwuFyHk5OR07NgxumMBSmNubu7i4kLPtjFNjh49Ss8OAwDkFhQURFeKoHnMEsNoF8Pk5+eHhIQo9rkUFBQEBQUpPSQlYrFYR48eXbJkCd2BjAzBwcE0bh3Gm4DSMDwxgZEFchMAgIkgNwEAmAhyEwCAiSA3AQCYCHITAICJIDcBJSgqKjI3N7958ybdgShTWVlZaWlpXl6era0ti8Vyc3Pr7u6mlj59+nTbtm36+vo6OjoxMTECgUD9Eba1tcXFxX300Ud92g8fPmxvb29gYODk5PTDDz+QxpqamtTU1BE0awdyE1ACPT29SZMmaWtrq24Tzc3Nquu8v8zMzLt37y5atGjp0qVnz57V0NC4cOHC1q1bqRWMjIySkpLCwsJ4PN6+ffvItHh1Ki0tjYiI+Oyzzzo6OqTbU1JScnJyVqxYsXr16t9++83Pz6+8vBwhNGfOnFmzZsXGxqo5ToVBbgJK4OXldeXKFQsLCxX139raqs4ivydPnqyoqIiKiiI/crlcUlkhJSWlsLBQes2pU6e++uqragtM2qJFi7Kzs/s0dnR0/Pvf/z558uTGjRtTU1PLy8tZLNaePXvIUk9PT319/fT0dLUHqwioZQGYTiQSLV26tKGhQT2ba29vX7NmTUVFhXSjtbW1hYVFcXHx6tWrZ86caWVlRdp1dHSkL/TUrH+l9kuXLiUlJVEPDXRxcZkzZ84ff/xBrRATE2Npaenj42Npaam+QBUC501guFpbW7/66isvL6+ioiKE0LVr1z788ENLS8vOzs6wsDAul+vo6EgyS319/ccff2xjY9PU1BQQEGBkZOTo6FhdXY0QOnLkiIGBgbm5OUJIKBTGx8dzOBxyl+mJEydu3rwpEAj4fP4XX3yBELpw4YK5ufmpU6dUsTvZ2dlaWlo2NjbSjWw2OycnZ8aMGc+ePQsMDHz+/PlL31tYWLh+/fotW7b4+PjExcWJxWLZBwQhhDHOysqKiopycnLy9va+c+fOcIKfN2+eg4ODdIuhoeG0adOoH/X09Ozt7T/77LPhbEVN6LqRj9zrS9fWwUAU+Fzq6+ujo6MRQgUFBRjj5ubm+fPnI4TWrVt348aNmpoaLS2tpUuXYoy3bds2btw4DocTHR1dWVlZWFjI5XJ1dXWbmpowxt7e3mZmZlS3dnZ2zs7O5LWfn9+0adOoRSdPntTR0cnNzR3q3iGEjh49KnsdFxeX4ODgPo2zZ8/GGDc0NEyYMAEhxOPxSHtWVtb+/fvJ65SUFFdX166uLoyxQCCwsrJyd3fv7e2VcUAwxomJid988w3GuLu728bGxsTEpLOzU87defHiBUJo/fr1A63Q3d09ceLEQ4cOSTfGx8cbGhp2d3cP2n9QUBCN9/rCeRMYrtdff/2dd96hfjQxMSF/unft2mVjYzN79mwHB4crV64ghBITE319fdlsdnJysoeHx7vvvpuZmSkSibKyshBCurq60t3q6ekNtEVfX9/29nZVVCXv7e399ddfSQLqz8LCoqCgQFNT89tvv+0z1vP48eO4uLjIyEjyyJkJEyZs37797Nmzubm5Mg5IU1NTamoqKX3F4XCCgoIePnxYWlqqrN0pLi6ePXv2ypUrpRuNjY2FQmF9fb2ytqIikJuAEvQpwkue9Es1mpmZtbe3k9e6urocDod6ZlRAQICWltb169eHusWXPkx4+FpbWyUSyfjx4wdawcPDIy0tDSG0YcOGq1evUu3V1dWdnZ1TpkyhWvz8/BBClZWVaOADUlVVJZFIIiIi+Hw+n89vamoKCwtT1iNqWltbExISvv/+e2r4iRg3bhxCiBQpZTIYCwd00tDQmDx5Mo3DyX2QJNLT0yNjncjIyLq6uszMzODgYD6fr6+vjxC6d+8eQujp06fUatTlqoyubt68qaen1//rNqWIjo5OTU01Njbu085msxFC/Z/GzDRw3gRoJhKJpk+fTncU/8PQ0FBbW7utra1PO/7zlMW0tDQPD4+GhgZqUJnMn+j/ZaLsXdPV1W1sbGxsbJRubGlpUSx4aenp6QEBAW+99Vb/RSSBmpiYDH8rKgW5CdCpubm5paWFFH7S0NDo6Oigzlk6Ojqov+1sNrvPDEMV/dlnsViurq59TnYwxiKRSLpFQ0OjoKDAwsKCisrFxcXAwIB8U0k0NjaKRCJ/f38Zm7Ozs8MYS8+HvHv3bkZGxjD34vDhwzo6OgEBAVQLmX5JCAQCAwMDW1vbYW5F1SA3ASUgk7apP/hCoRAhRF2pPX78WPp3WywW19bWktcJCQk8Hs/R0REhZGdn19bWlpiY+PvvvyckJIjF4tu3b9fU1CCEJk+eLBAIrly5cubMGZFIVF5ePn78+IKCAlXsS2hoaFVVlfSJUmNj48OHD6WfXYwQmjBhQklJydixY6kfk5OTL1y4cPr0adKSlpbG4/E8PT1lHBAvLy8HB4fDhw8HBgbm5ORkZGRERESsW7cOIbR27Vo3NzfpqUn9dXZ2on5XoD/88MM///lPiURy4MCBAwcOZGVlrV279tatW9QKVVVVgYGBKhqwUya6viCEOQTMpMDncvr0aXLtYG9vX1ZWVl5eTibUrF279vHjx9999x35Bf7kk0+6u7vDwsLGjBkTHR0dHBy8Zs2a+Pj43t5e0o9QKFy0aNHYsWOdnZ0vX768cuXK5cuXl5SUYIxra2vNzMysra2PHTuGMa6oqDA1NS0qKhrq3iE55hB0dXVZWVmR9IQxPn78uLu7O0IoKCjo559/7rNyUVFRenq69I/e3t7r16/fsWPH3r17ya7JPiBPnjx57733Jk2aNHHixPfff//Bgwekq4ULF7LZ7NjY2IHiLCsrI3PlLS0tDxw4QOZh/PLLL/2H0rW0tJ48eULeJRKJjIyMbt26Jc/honcOAeQm8Ceq/lzCwsK0tbVV179s8uQmjPHly5f9/f3VEI9s586dS0pKUm6fcXFxe/bskXNlmN80NNS30QCoiL29fWhoaEpKCo0xtLe3l5aWUvf0KcWpU6ckEsmWLVuU2KfqjKTcdODAAXd399dff53uQBAaoAyFbMePH/f09GSxWGTA1c3Nbc6cOc7OzrGxsXfv3lV1wAzR0dEhkUgw4yt1hISE2NralpSU0BVAXV3dp59+amBgoKwOa2trhUJhUlKSsjpUObpO2BS4duju7nZzczMxMVFRSPLbt2+fj49Pamrqxo0bdXV1WSzWTz/9JM8bybfFU6dOpVp++eWXt99+m8PhbN++vaenR1URy02l13QZGRlkynVYWFj/sRs1QPJd0wGC3mu6kTT3ksPhmJmZyf7mQg1IGQpSfQIhFBIS4ubmtmfPHnLPlGzkPgzp0UoHB4eTJ0+uWLHi888/Hzt2bP86YaNJVFSUci9SwCg2kq7pGGLQMhQy9Ll7gGCz2RkZGZMmTUpISLh//74yYwVgxBoBuam4uDg8PDw2NnbDhg3SxQ/xy4pLyK5Hce3atVWrViUnJ7/zzjteXl4y+pFBdhkKxcp3GBoaLlmyRCQS5efn07hrADAIXReTco5r5ObmOjk5PX/+HGPc0tLC5XKp8aaXFpeQXY/C2tr6/PnzGGORSOTm5iajH/l3pE8ZCtnlO8jNENOnT++/KCcnByG0atUqendtdM/tQDDeNBQwv2lAnZ2dpqamhw8fploWL15MctODBw+MjY2pweOdO3cihPLy8jDGZMhGIBCQRW5ublZWVhjjrq4uFov15ZdfkvYTJ07I7kdOhYWFXl5e1ARCjLGMyjgyctOPP/6IEJo3bx69uwa5CVBgLHxAP//8c3Nzs52dHdVCFSGliktQi6jiEv3rUZDBIE1NzQULFmzatOm3335LSkoidxvJ6EcepAzFqVOnpAeSFLsbgNzWYG1tzYRdCw4OVmAXRoSUlJRjx47RHcXIUF1d7ezsTNfWGZ2byE1AY8aM6b9IseIShYWFfD4/Ozv7xIkT+fn5np6ewyxSMVAZCgWQByjNmjWLIbsGAL0YnZtIVrp37561tXWfRVRxCTMzM6qxpaVl4sSJMjrU0NDIzc1duHDh5s2b33777WvXrinWDyGjDMVQYYxJQcW33367oKCA9l0brWcWLBYrOjp6yZIldAcyMtB7+szo7+lmzpyJECIjIERvby+561qB4hJisfjgwYMIodDQ0OrqaoxxZWWlwkUqZJShkFG+Aw8wH3rv3r3Xr1+PjY2dOnUq7bsGABMw+rxp7ty5np6e33zzzRtvvMHj8W7cuHH+/PmWlpYjR474+/uT4hIvXrxYvHjxs2fPjh8/npeXh2QW6Dh06FBUVBSHw5k8ebKhoeHf/vY3JyengfqRgZShWLly5YEDBxBCGOO6ujobG5v58+eXl5cHBgZ+9dVXpCZRH6Tcj3TBkHv37u3du3f//v0bN27ctWsXkqqbQcuuAcAUdA3Cy/l9kFAoXLVqlbGx8ZQpUz755JPw8PBVq1aVl5f39PS8tLiEjHoUnZ2dDg4OCxYsSEpKCg8Pz87OJpsYqEjFQGSXoZBRvqOoqIhU80EIubm5zZs3z9fX18fHJyYmpra2VnpNunZN/s9lhELwPd1Q0Ps9HQvTdNdlfn5+SEgIXVsHAxndnwuLxTp69CiMN8mJjDfRNfjI6Gs6GskYMD506NCiRYvUGQwAf0GQm15OKfXkwWhSVlYmFos7Ozvj4+Pr6+vnzp175swZaq7Z06dPd+/enZ6e3t3dHRUVtX37di6Xq87wjh07VlZWxuVy//Of/1hZWe3YsUNTU7Ompubs2bMbN2586Y2cDAe5CahVc3OzqakpEzoZkszMTIQQKaIwf/58U1PTCxcubN26dd++fWQFIyOjpKQksVj8/PlzqlFt8vPzd+/efenSJQ6HgzFeuHBhXFxccnLynDlz2traYmNjd+/ereaQho/RcwjAKNPa2kpKXNPeyZCcPHmyoqKCqu7C5XLJ6VJKSkphYaH0mlOnTn311VfVGRtx8OBBFxcXctsAi8Xy8fEpLi4mizw9PfX19dPT09Uf1TDBeRNQE5FItHTp0v5PcFN/J0PS3t6+Zs2aiooK6UZra2sLC4vi4uLVq1fPnDnTysqKtOvo6NDyHND29vby8nKJREIemFxXV/fKK69QS2NiYiwtLX18fCwtLdUfm8LgvAkoqLCwcP369Vu2bPHx8YmLixOLxQihI0eOGBgYmJubI4SEQmF8fDyHw3FxcUEInThx4ubNmwKBgM/nf/HFF/X19R9//LGNjU1TU1NAQICRkZGjo2N1dfWQOkGKFqWRX3Z2tpaWlo2NjXQjm83OycmZMWPGs2fPAgMDnz9/Lv8hkl3rBitU1obP59+6dcvX11coFFZXV1+6dEm62Lmenp69vT31mM8Rg67JC6N7Hs3IJefnkpKS4urq2tXVhTEWCARWVlbu7u6kGIO3t7eZmRm1pp2dnbOzM3nt5+c3bdo08nrbtm3jxo3jOoErYwAAHTdJREFUcDjR0dGVlZWFhYXUQ7rl7wQPVpSmDzT0+U0uLi7BwcF9GmfPno0xbmhoICWGeTweac/Kytq/fz95PdAhkl3rRuGKPWTirrW1tZ+fX2tra5+l8fHxhoaGMipkvBQ8ZwWMMI8fP46Li4uMjCRXEBMmTNi+ffvZs2dzc3MRQrq6utIrkzLE/SUmJvr6+rLZ7OTkZA8Pj3fffTczM1MkEmVlZcnfCULI19e3vb09NDR0+PvVX29v76+//koSUH8WFhbkLshvv/22zz3VMg6RiYkJqU24a9cuGxub2bNnOzg4XLlyBSHU1NSUmpq6YsUKhBCHwwkKCnr48GFpaak8oe7cudPV1fXOnTtnzpy5evVqn6XGxsZCobC+vn7ox4A2kJvAkFVXV3d2dk6ZMoVq8fPzQwhVVlYOqR9dXV0Oh0N+exFCAQEBWlpa169fH2o8qntEbWtrq0QiGT9+/EAreHh4pKWlIYQ2bNggnRFkH6L+tW7Ik82osjZ8Pp/P5zc1NclZ1qa7u3vVqlUrV6788ccftbS0fH19qbFwYty4cQihR48eDWHn6QZj4WDI7t27hxB6+vQp1UJdjg2nWw0NjcmTJ9MyljwQkkT6PNS7j8jIyLq6uszMzODgYD6fr6+vjxQ9RAqXtdm0adP9+/e//vprhNC5c+e8vLx4PN79+/epR0ix2Wwk8y50BoLzJjBkFhYWCKH+X5ZNnz59mD2LRKLhd6JEhoaG2trapFqpNPzne3rS0tI8PDwaGhqo8WbFDhFV1ka6UZ5pwHl5eeS7AoSQjY1NYmKiUCisqamhViBZ0sTEZNCumANyExgyFxcXAwODoqIiqqWxsVEkEvn7+yOENDQ0Ojo6qHONjo4O6s81m80mlRheqrm5uaWlhdRvGFInqjsdIE857XOygzGWriRBoi0oKLCwsKACk32IBqJwWRsulyv9vGt7e3uE0KRJk6gWgUBgYGBga2s7aFfMAbkJDNmECROSk5MvXLhw+vRp0pKWlsbj8UiVBTs7u7a2tsTExN9//z0hIUEsFt++fZv8DZ88ebJAILhy5cqZM2fIr7dYLK6trSWdJCQk8Hg8R0fHIXVSXl4+fvz4goICFe1saGhoVVWV9IlSY2Pjw4cPJRJJn2NSUlJCKkMMeogGqnVDlccJDAzMycnJyMiIiIhYt24dQmjt2rVubm4DPWosPDz8yJEj1BlWWVnZm2+++dprr1ErVFVVBQYGqm5gTiXo+oIQ5hAwk/yfS1FRkbe39/r163fs2LF3717qaQ5CoXDRokVjx451dna+fPnyypUrly9fXlJSgjGura01MzOztrY+duwYxjgsLGzMmDHR0dHBwcFr1qyJj49XoBMZRWn6Q0OfQ9DV1WVlZUXSE8b4+PHj7u7uCKGgoKD+jyYuKipKT0+XfYhk1Lrp7u4eqKzNwoUL2Wx2bGzsQHEeOHBgwYIFmzdv3rp16wcffEAq9hAikcjIyOjWrVtD2nFM9xwCyE3gT9T5uYSFhWlra6tnW4QCuQljfPnyZX9/f1XEMyTnzp1LSkpS4I1xcXF79uxR4I0wvwkARrO3tw8NDZWeaa1+7e3tpaWlCjyx/dSpUxKJZMuWLaqISqUgNwHadHR0SCQSPBLq2IWEhNja2paUlNAVQF1d3aeffkrNCZBTbW2tUChMSkpSUVQqBfObAD0yMzN/+umnnp6e8PBwHo/n5uZGd0SD8Pb2pnHrc+fOVeBds2bNmjVrltKDUQ/ITYAeUVFRClyhgL8OuKYDADAR5CYAABNBbgIAMBHkJgAAE0FuAgAwEl2TPsn8YwAAk/0Vn+vb2NhYVVVFy6aBioSEhGzatIkq1gFGAXNzc7o+UNpyExh94IneQIlgvAkAwESQmwAATAS5CQDARJCbAABMBLkJAMBEkJsAAEwEuQkAwESQmwAATAS5CQDARJCbAABMBLkJAMBEkJsAAEwEuQkAwESQmwAATAS5CQDARJCbAABMBLkJAMBEkJsAAEwEuQkAwESQmwAATAS5CQDARJCbAABMBLkJAMBEkJsAAEwEuQkAwESQmwAATAS5CQDARJCbAABMBLkJAMBEkJsAAEwEuQkAwESQmwAATKRBdwBgBDty5Eh7e7t0S3l5eVtbG/Xj4sWLJ06cqPa4wGjAwhjTHQMYqVauXPntt99qamqSH8n/JRaLhRDq6ekZO3bs48ePtbS06AwRjFhwTQcUt2zZMoSQ5H91d3d3d3eT1xwOJzg4GBITUBicNwHFdXd3GxsbP3369KVLT58+/fe//13NIYFRA86bgOI0NDSWLVtGXdNJ43K57u7u6g8JjBqQm8CwLFu2TCKR9GnU1NRcsWIFh8OhJSQwOsA1HRgWjPGUKVMaGxv7tP/yyy8ODg60hARGBzhvAsPCYrGWL1/e57LO3Nzc3t6erpDA6AC5CQxXn8s6TU3NlStXkpkEACgMrumAEkyfPv327dvUj7/99putrS2N8YBRAM6bgBKsWLGCuqyzsbGBxASGD3ITUILly5d3d3cjhDQ1NXk8Ht3hgNEArumActjb21+5coXFYv3nP/+ZMmUK3eGAEQ/Om4ByvP/++wghJycnSExAKZhSh2Dfvn0XL16kOwqguBcvXrBYLLFYHBwcTHcsYFiOHTtGdwgIMee86eLFi9XV1XRHAfqqrq6W83PR1tY2NjY2MzNTdUjK0tjYWFBQQHcUzMKoY8KU8Sbyx5YhCRtQhvS5/PHHH6+++qqKI1Ka/Pz8kJAQhvz/ZwhGHROmnDeBUWAEJSbAfJCbAABMBLkJAMBEkJsAAEwEuQkAwESQm4CSFRUVmZub37x5k+5AlKysrKy0tDQvL8/W1pbFYrm5uZHbdIinT59u27ZNX19fR0cnJiZGIBCoObxjx47x+fyPPvpo2bJlO3fuJJUhampqUlNTGfK921AxZe4lGDX09PQmTZqkra2tuk00Nzebmpqqrv/+MjMzEUJRUVEIofnz55uaml64cGHr1q379u0jKxgZGSUlJYnF4ufPn1ONapOfn7979+5Lly5xOByM8cKFC+Pi4pKTk+fMmdPW1hYbG7t79241hzR8cN4ElMzLy+vKlSsWFhYq6r+1tXX58uUq6vylTp48WVFRQRITQojL5WpoaCCEUlJSCgsLpdecOnUqLRMpDh486OLiQoogs1gsHx+f4uJissjT01NfXz89PV39UQ0TnDeBkUQkEi1durShoUFtW2xvb1+zZk1FRYV0o7W1tYWFRXFx8erVq2fOnGllZUXadXR0pC/01BlkeXm5RCIhlWrq6upeeeUVamlMTIylpaWPj4+lpaX6Y1MYnDcBZWptbf3qq6+8vLyKiooQQteuXfvwww8tLS07OzvDwsK4XK6joyPJLPX19R9//LGNjU1TU1NAQICRkZGjoyO5P+bIkSMGBgbm5uYIIaFQGB8fz+FwXFxcEEInTpy4efOmQCDg8/lffPEFQujChQvm5uanTp1S0R5lZ2draWnZ2NhIN7LZ7JycnBkzZjx79iwwMPD58+cvfW9hYeH69eu3bNni4+MTFxcnFotlHxOEEMY4KysrKirKycnJ29v7zp078gTJ5/Nv3brl6+srFAqrq6svXbqUkpJCLdXT07O3t//ss88UPAR0wcwQFBQUFBREdxSgr6F+LvX19dHR0QihgoICjHFzc/P8+fMRQuvWrbtx40ZNTY2WltbSpUsxxtu2bRs3bhyHw4mOjq6srCwsLORyubq6uk1NTRhjb29vMzMzqls7OztnZ2fy2s/Pb9q0adSikydP6ujo5ObmDnXXjh49Ks//fxcXl+Dg4D6Ns2fPxhg3NDRMmDABIcTj8Uh7VlbW/v37yeuUlBRXV9euri6MsUAgsLKycnd37+3tlXFMMMaJiYnffPMNxri7u9vGxsbExKSzs1Oe3dm1axdCyNra2s/Pr7W1tc/S+Ph4Q0PD7u5u2Z3IeUzUgylxQG5iJgU+lzNnzlC5CWP80UcfIYQEAgH50c3NzcrKirwODQ3V1NQkv70YY3LX3s6dOzHGAQEB0rnJ2dl5oNyEMR70V+6l5Pk97Onp0dTUjIyM7NNOchPGuLKyklxGHTx4EEvlpkePHunp6X333XfUW77++muE0Pfff48HPiYPHjwwNjbu6ekh7Tt37kQI5eXlyblHrq6uLBZr7Nixp0+f7rPo4MGDCKG6ujrZPTAqN8E1HVAyMk5MIQO0VKOZmVl7ezt5raury+FwqGK+AQEBWlpa169fH+oWVfcgvNbWVolEMn78+IFW8PDwSEtLQwht2LDh6tWrVHt1dXVnZ6d0KSs/Pz+EUGVlJRr4mFRVVUkkkoiICD6fz+fzm5qawsLCdHR0Bo2zu7t71apVK1eu/PHHH7W0tHx9famxcGLcuHEIoUePHg1h5+kGY+GAKTQ0NCZPnkzLWPJASBLp6emRsU5kZGRdXV1mZmZwcDCfz9fX10cI3bt3DyEk/TR26opVRlc3b97U09PLzs4eapybNm26f/8+OTU7d+6cl5cXj8e7f/++gYEBWYHNZiOEent7h9ozjeC8CTCISCSaPn063VH8H0NDQ21t7ba2tj7t+M+zGdPS0jw8PBoaGqjxZjKFov/3ibL3TldXt7Gxsc+DSFtaWgaNMy8vj3xXgBCysbFJTEwUCoU1NTXUCiRLmpiYDNoVc0BuAkzR3Nzc0tISFBSEENLQ0Ojo6KBOWDo6Oqi/+Ww2u6OjQ/qNqjsdYLFYrq6ufU52MMYikUi6RUNDo6CgwMLCggrMxcXFwMCAfFlJNDY2ikQif39/GZuzs7PDGMfGxlItd+/ezcjIGDROLpdLXSkjhMiDSydNmkS1CAQCAwODkfX8G8hNQMmam5uR1F97oVCIEKKu1B4/fiz9iy0Wi2tra8nrhIQEHo/n6OiIELKzs2tra0tMTPz9998TEhLEYvHt27fJicDkyZMFAsGVK1fOnDkjEon+f3vnHtTE9cXxS4KAPII8FGQoCFOi5WGkQyzWVKAMQV6W8hAmpQ3ISxFqQUacijMoWMNQCoUCMvRdwA7yEsZx5Fl5t9Qi6FjaqlNbihRQTBOiEGF/f9zfb38pyBISkmzwfv5K7u6enHuWPezePfd7W1pajIyMFKfWyOFwenp6JG+URkZGxsbGJJcLBQCYmJg0NDTo6+vjX7Ozs7u7u1tbW2FLQUEBl8v18PAAS8fEy8uLyWRWVlYGBweXl5cXFxfHx8cfPnwYAJCQkMBisW7fvv1MJ+Pi4s6fP4/HvKmp6bXXXtu6dSu+Q09PT3BwsOIG5hSCaoficdB7OnKy0vPS2tq6Z88eAICLi0tTU1NLS8uWLVsAAAkJCePj419//TW8ejMyMp4+fRoTE6OlpZWcnBwaGhodHZ2ZmTk/Pw/t8Pn8gIAAfX19V1fX/v7+yMjIiIiIhoYGDMMGBwctLS3pdPqFCxcwDGtra9u8eXN9ff1KuyblO6nZ2Vk7OzuYnjAMq62tdXNzAwCEhIR0dnYu2Lm+vr6oqEjyK5vNTkxMPHnyZG5uLuwdcUwePHjw1ltvbdq0aePGje+8885ff/0FTfn5+VEolLS0tKX8LC0t9fb2Pnr06LFjx959990HDx7gm0QikbGx8fDw8GrFRDmQxQ+Um8iJQs9LTEyMjo6Ogowvi/TXYX9//759+xTtz7J0dHTweDwZDkxPT8/JyZFmT1LlJvRMh0Asg4uLC4fDkay0Vj4CgaCxsRGf0yc9ly9fFovFqampivBKoah9bpIcAkSoF0KhUCwWY+qg4BEWFubg4NDQ0KAqB4aGhk6fPo3XBEjJ4OAgn8/n8XgK8kqhqHFuKi0tdXNze+mll1TtCAAAXLhw4eWXX9bX12cwGAvK3paitrbWw8NDQ0MDvgxisVjOzs6urq5paWl37txRtMMqp6SkpLm5eW5uLi4urqurS9XuLA+bzSZ+y6ZQdu/eLYPsDIPBCA8PV4Q/SkCNc1NMTMz8/DxxXZxy+PLLLzs6Or744ovGxkYqlRoaGirNFM2goKDy8nIAgLW1dU9PT1dX18DAQGFh4dDQ0NatW0+cOKFelXIr5dChQ3DSRllZGYvFUrU7CNKhxrmJSqWSYaVGsVh8+/btwsJCBoPh4eHx6aefisXi77//Xppj9fT0AACSkxKYTOalS5fCwsI++OCD7OxsRTmNQJAeNc5NJIFCoWRkZOBf4cR0JpMpzbEaGhrPNFhcXLxp06asrKw//vhjldxEINQM9ctNFy9ejIuLS0tLS0pKgmV+EOxZwjfEWjnXr1+PiorKzs5+4403vLy8COwQQKVSJWe3VlZWFhYW4mVvsqkLGRoa7t+/XyQSVVVVqbBrCIQqUWUBgwRS1tFUVFS88sorjx8/xjBsYmLC1NTU3Nwcbnqm8A2xVg6dTu/q6sIwTCQSsVgsAjvSdEEgEJw6dcrMzOzKlSt4I7G6EJyotW3btsWb4FBUVFSUaru2huvOSFXLQxJIFROy+CHNNTA9Pb158+bKykq85c0334S5iUD4ZimtnNnZWQ0NjY8//hi219XVEdshRigUpqam+vr6amlpAQA+++wzfBOBuhBBbrpy5QoAwNPTU7VdQ7npuYJUMVEnjZTOzs779+87OTnhLdra2vADLnyDb8KFbxZr5cBJSevWrfP29n7vvfdu3rzJ4/ECAwOJ7RCjp6eXk5MDALh586abm9uZM2cOHDgAN8k2iQlOuaLT6SrvWnV19TPHxdYGa7hr6o465abh4WEAALwxWYBswjc1NTWxsbFlZWV1dXVVVVUeHh4yC+jgODo6HjlyJCMjAxeWlw24vhuDwVB511xdXaHM7hqjt7c3Pz8f3ikgIDAmqvbiv6hTboJZ6d69e3Q6fcEmXPhGsqpgYmJi48aNBAY1NTUrKir8/PyOHj26d+/e69evy2ZnAY6OjpaWlvIkJgzDqqur161bt3fv3urqatV2zdLScv/+/TL3hczk5+ev1a7JDHlykzq9p9u+fTsAQPIfHV57KYPwzczMDBRR5nA4fX19GIa1t7fLLKAjyfDwsGQBMUEJJbbEdI3c3NwbN26kpaVZW1uTqmsIhPJQ3VDXv5ByzNXDw4NKpRYXF09PT//www8WFhYAgMrKSqFQCEuKgoKCvvnmm6KiIk9Pz4mJCQzDkpKSgMSA8euvv06j0TAMe/LkibOzMxyonp2dNTU17e3tnZ+fX8rOUkxNTUVGRtbU1EAFjN9++43NZguFQri1ubmZRqNBNY/F/PnnnwAAKysrvOX3339PSkrS0NA4cuQIHLcmcEnRXcPQWPhzBqliQhY/pLwG+Hx+VFSUmZmZlZVVRkZGXFxcVFRUS0vL3NzcM4VvCLRypqenmUymt7c3j8eLi4srKyuDP7GUgM5SCAQCf39/ExOTPXv2ZGZmlpeXw/mrEAJ1ofr6eqg0BgBgsVienp6+vr4+Pj4pKSmDg4OSe6qqaxjKTc8ZpIqJBkaOWeChoaEAALgKEII8rOHzUlVVFRYWRpK/f5JAqpio01i4CiEYMP78888DAgKU6QwC8TygTmPhKmRiaVBiek5oampqbGz89ttvHRwcNDQ0WCyW5HJVDx8+PH78uIGBwfr161NSUiYnJ5Xv4aNHj9LT02FFLmRgYCA/P58k90ErBeUmhCqRnBGpWiPElJSU3LlzJyAgIDw8/OrVq5qamt3d3ceOHcN3MDY25vF4MTExXC73o48+MjU1VbRLC2hsbIyPjz9z5ozkIjTOzs4MBkPy5awagXITQmVMTU1FRESQwQgxly5damtrw/VwTU1NYS1+Xl5eTU2N5J7W1tYvvviiQp1ZioCAgGcW1np4eBgYGBQVFSnfJTlB400I1SASicLDwxevLql8I8QIBILo6Oi2tjbJRjqdbmNjc/HixQMHDmzfvt3Ozg62r1+/XoXrEuNTuBaQkpJia2vr4+Nja2urZJfkAd03IVaHmpqaxMTE1NRUHx+f9PT0mZkZAMD58+dpNNoLL7wAAODz+ZmZmVQqFa5AW1dX9/PPP09OTsbGxn744Ye3bt06ceKEvb396OhoYGCgsbHxzp07+/r6VmQEyCpKQ0BZWZm2tra9vb1kI4VCKS8vd3R0/Oeff4KDgx8/fix9TIjFbTAF6Njo6em5uLjgaw6rDSqtYPg/a7iORq2R8rzk5eW9+uqrs7OzGIZNTk7a2dm5ubnBYlQ2m21paYnv6eTk5OrqCj/7+/tv2bIFfj5+/PiGDRuoVGpycnJ7e3tNTY2pqamuru7o6Kj0RrDlRGkkkbKWZ9euXaGhoQsad+zYgWHY3bt3oZQgl8uF7efOnfvkk0+IY0IsbiOzRA+GYU+ePAEAJCYmLt6UmZlpaGhIIIkBIVV9E7pvQsjL+Ph4enr6wYMH4RRCExOT999//+rVqxUVFQAAXV1dyZ2hDPFizp496+vrS6FQsrOz3d3dg4KCSkpKRCLRuXPnpDcCAPD19RUIBBwOR/5+AQDm5+d//PFHmIAWY2NjA6c9fvXVVwvGeghiYm5uDgv0T506ZW9vv2PHDiaTee3aNQDA6Ohofn7+22+/DQCgUqkhISFjY2ONjY3yd8TMzIzP59+6dUt+U0oD5SaEvPT19U1PT1tZWeEt/v7+AID29vYV2dHV1aVSqfgc6cDAQG1t7Rs3bqzUn1VcWXtqakosFhsZGS21g7u7e0FBAQAgKSnpp59+wtuJY7JY3AYuZYbr2MTGxsbGxo6OjkqpY7MsGzZsAAD8/fff8ptSGmgsHCEv9+7dAwA8fPgQb8Efx+Qxq6mpaWFhocKhZfC/JEK8ls/BgweHhoZKSkpCQ0NjY2MNDAyArDGRX6JnKSgUCiCcdk5C0H0TQl5sbGwAAItflm3btk1OyyKRSH4j8mBoaKijowPlSSXB/l3NWFBQ4O7ufvfuXXy8WbaY4Do2ko0TExOyOS8JzJLm5ubym1IaKDch5GXXrl00Gq2+vh5vGRkZEYlEUChGU1NTKBTitx5CoRD/702hUCQLBRdw//79iYmJkJCQlRpZxbsDuKzpgpsdDMNEIpFki6amZnV1tY2NDe4JcUyWQnE6NpOTkzQazcHBQX5TSgPlJoS8mJiYZGdnd3d3t7a2wpaCggIulwtVFpycnB49enT27Nlff/01KytrZmbml19+GRgYAABYWFhMTk5eu3btu+++g1f7zMzM4OAgNJKVlcXlcnfu3LkiIy0tLUZGRtXV1avVOw6H09PTI3mjNDIyMjY2JhaLFwShoaEBSkEsGxMouIw/ro6Pj8Pue3l5MZnMysrK4ODg8vLy4uLi+Pj4w4cPAwASEhJYLBbUXF6K6elpsMQTaE9PT3Bw8CqOxCkD1b4mxEE1BORE+vNSX1/PZrMTExNPnjyZm5sLCwgwDOPz+QEBAfr6+q6urv39/ZGRkREREQ0NDRiGDQ4OWlpa0ul0qG8VExOjpaWVnJwcGhoaHR2dmZkpgxECUZoFSPm+fHZ21s7ODqYnDMNqa2vd3NwAACEhIZ2dnYuDUFRURBwTAnGbp0+fLqVj4+fnR6FQ0tLSlvKzqakJ1sfb2tqWlpbC2guISCQyNjYeHh5erZgoB7L4gXITOVHmeYmJidHR0VHOb2EruQ77+/v37dunaH+WpaOjg8fjyXBgenp6Tk6ONHuSKjehZzoEYhlcXFw4HE5eXp4KfRAIBI2NjficPum5fPmyWCxOTU1VhFcKBeUmBFkQCoVQMlTVjjyDsLAwBweHhoYGVTkwNDR0+vRpGo22oqMGBwf5fD6Px1OQVwoF1TchSEFJSUlzc/Pc3FxcXByXy2WxWKr2aCFsNluFv757924ZjmIwGAwGY9WdUQ4oNyFIwaFDh2R4YEGsYdAzHQKBICMoNyEQCDKCchMCgSAjKDchEAgyQqKx8JGRkaqqKlV7gfgXcN7pmjwvvb29YI12TWZgTEgCidbOXMU5UAgEQmZIkhPIkpsQCARCEjTehEAgyAjKTQgEgoyg3IRAIMgIyk0IBIKM/AeZQI6WcwMG2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize our model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmed/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4740 - accuracy: 0.7734\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4631 - accuracy: 0.7826\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.4649 - accuracy: 0.7904\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4778 - accuracy: 0.7773\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4709 - accuracy: 0.7617\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4654 - accuracy: 0.7799\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4635 - accuracy: 0.7773\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4589 - accuracy: 0.7865\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4562 - accuracy: 0.7747\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4643 - accuracy: 0.7917\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.4541 - accuracy: 0.7904\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.4611 - accuracy: 0.7747\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4724 - accuracy: 0.7878\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4563 - accuracy: 0.7865\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4601 - accuracy: 0.7734\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4665 - accuracy: 0.7826\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4559 - accuracy: 0.7839\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4547 - accuracy: 0.7891\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4646 - accuracy: 0.7812\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4583 - accuracy: 0.7878\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4626 - accuracy: 0.7747\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.4526 - accuracy: 0.7812\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4825 - accuracy: 0.7591\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 231us/step - loss: 0.4578 - accuracy: 0.7786\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4550 - accuracy: 0.7852\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4720 - accuracy: 0.7760\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4579 - accuracy: 0.7839\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.4527 - accuracy: 0.7839\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4612 - accuracy: 0.7747\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4647 - accuracy: 0.7708\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4585 - accuracy: 0.7878\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4584 - accuracy: 0.7826\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.4546 - accuracy: 0.7747\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 263us/step - loss: 0.4631 - accuracy: 0.7734\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 231us/step - loss: 0.4534 - accuracy: 0.7891\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.4543 - accuracy: 0.7878\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 267us/step - loss: 0.4462 - accuracy: 0.7865\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.4492 - accuracy: 0.7812\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.4641 - accuracy: 0.7799\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 152us/step - loss: 0.4525 - accuracy: 0.7812\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4524 - accuracy: 0.7747\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4469 - accuracy: 0.7891\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4508 - accuracy: 0.7852\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.4526 - accuracy: 0.7734\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.4493 - accuracy: 0.7878\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4564 - accuracy: 0.7760\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.4524 - accuracy: 0.7747\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4543 - accuracy: 0.7839\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 145us/step - loss: 0.4462 - accuracy: 0.7747\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.4443 - accuracy: 0.7930\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 246us/step - loss: 0.4601 - accuracy: 0.7852\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4571 - accuracy: 0.7865\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4555 - accuracy: 0.7773\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.4565 - accuracy: 0.7839\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4492 - accuracy: 0.7852\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4401 - accuracy: 0.7943\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.4575 - accuracy: 0.7747\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4541 - accuracy: 0.7734\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4503 - accuracy: 0.7812\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4448 - accuracy: 0.7721\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4423 - accuracy: 0.7786\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4442 - accuracy: 0.7773\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4451 - accuracy: 0.7956\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4492 - accuracy: 0.7760\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4435 - accuracy: 0.7852\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4469 - accuracy: 0.7786\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4467 - accuracy: 0.7852\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4429 - accuracy: 0.7891\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4379 - accuracy: 0.7982\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4399 - accuracy: 0.7799\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4509 - accuracy: 0.7904\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 158us/step - loss: 0.4575 - accuracy: 0.7734\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.4451 - accuracy: 0.7865\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4400 - accuracy: 0.7865\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4435 - accuracy: 0.7747\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.4513 - accuracy: 0.7812\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 165us/step - loss: 0.4449 - accuracy: 0.7839\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4489 - accuracy: 0.7852\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4468 - accuracy: 0.7826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4481 - accuracy: 0.7839\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4380 - accuracy: 0.7930\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4444 - accuracy: 0.7760\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4501 - accuracy: 0.7865\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4343 - accuracy: 0.7956\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4374 - accuracy: 0.7878\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4437 - accuracy: 0.7930\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4536 - accuracy: 0.7747\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.4418 - accuracy: 0.7852\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4441 - accuracy: 0.7760\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.4418 - accuracy: 0.7878\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4354 - accuracy: 0.7917\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4569 - accuracy: 0.7826\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4388 - accuracy: 0.79820s - loss: 0.4251 - accuracy: 0.82\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4420 - accuracy: 0.8034\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4514 - accuracy: 0.7917\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4355 - accuracy: 0.7760\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4300 - accuracy: 0.7930\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.4393 - accuracy: 0.7760\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.4376 - accuracy: 0.7891\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4321 - accuracy: 0.7930\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 64us/step - loss: 0.4528 - accuracy: 0.7760\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 63us/step - loss: 0.4435 - accuracy: 0.7865\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 64us/step - loss: 0.4391 - accuracy: 0.7760\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 65us/step - loss: 0.4486 - accuracy: 0.7917\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.4552 - accuracy: 0.7786\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4323 - accuracy: 0.7930\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4344 - accuracy: 0.7917\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4363 - accuracy: 0.7812\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4300 - accuracy: 0.7878\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 71us/step - loss: 0.4381 - accuracy: 0.7826\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4343 - accuracy: 0.7891\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4367 - accuracy: 0.7865\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.4386 - accuracy: 0.7982\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 66us/step - loss: 0.4303 - accuracy: 0.7930\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.4449 - accuracy: 0.7773\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4347 - accuracy: 0.7904\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4283 - accuracy: 0.7930\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 81us/step - loss: 0.4354 - accuracy: 0.7904\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 62us/step - loss: 0.4370 - accuracy: 0.7826\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 59us/step - loss: 0.4355 - accuracy: 0.7878\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 62us/step - loss: 0.4292 - accuracy: 0.7930\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 64us/step - loss: 0.4370 - accuracy: 0.7930\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 63us/step - loss: 0.4329 - accuracy: 0.7956\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 64us/step - loss: 0.4378 - accuracy: 0.7917\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 72us/step - loss: 0.4363 - accuracy: 0.7982\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4309 - accuracy: 0.7995\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 70us/step - loss: 0.4374 - accuracy: 0.7734\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 60us/step - loss: 0.4425 - accuracy: 0.7969\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 61us/step - loss: 0.4541 - accuracy: 0.7773\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 59us/step - loss: 0.4357 - accuracy: 0.7865\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 57us/step - loss: 0.4291 - accuracy: 0.7917\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 58us/step - loss: 0.4350 - accuracy: 0.7865\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 69us/step - loss: 0.4259 - accuracy: 0.7852\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4285 - accuracy: 0.7865\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 81us/step - loss: 0.4317 - accuracy: 0.7773\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.4392 - accuracy: 0.7852\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4332 - accuracy: 0.7956\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.4389 - accuracy: 0.7982\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.4254 - accuracy: 0.7904\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4373 - accuracy: 0.7930\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4338 - accuracy: 0.7904\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.4341 - accuracy: 0.7878\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.4226 - accuracy: 0.8008\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4290 - accuracy: 0.7904\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.4363 - accuracy: 0.7917\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4320 - accuracy: 0.7930\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4337 - accuracy: 0.7865\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 65us/step - loss: 0.4317 - accuracy: 0.7904\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4350 - accuracy: 0.7865\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.4287 - accuracy: 0.7891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fdd2b6bf1d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 21us/step\n",
      "accuracy: 78.26%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1],scores[1]*100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tie all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.6771 - accuracy: 0.6510\n",
      "Epoch 2/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.6585 - accuracy: 0.6510\n",
      "Epoch 3/250\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.6474 - accuracy: 0.6510\n",
      "Epoch 4/250\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.6390 - accuracy: 0.6510\n",
      "Epoch 5/250\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.6324 - accuracy: 0.6510\n",
      "Epoch 6/250\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.6181 - accuracy: 0.6510\n",
      "Epoch 7/250\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.6190 - accuracy: 0.6510\n",
      "Epoch 8/250\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.6135 - accuracy: 0.6510\n",
      "Epoch 9/250\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.6087 - accuracy: 0.6510\n",
      "Epoch 10/250\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.6170 - accuracy: 0.6510\n",
      "Epoch 11/250\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.6055 - accuracy: 0.6510\n",
      "Epoch 12/250\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.6034 - accuracy: 0.6510\n",
      "Epoch 13/250\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5998 - accuracy: 0.6510\n",
      "Epoch 14/250\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6036 - accuracy: 0.6510\n",
      "Epoch 15/250\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5997 - accuracy: 0.6510\n",
      "Epoch 16/250\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5985 - accuracy: 0.6510\n",
      "Epoch 17/250\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5986 - accuracy: 0.6510\n",
      "Epoch 18/250\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5999 - accuracy: 0.6510\n",
      "Epoch 19/250\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.5970 - accuracy: 0.6510\n",
      "Epoch 20/250\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5990 - accuracy: 0.6510\n",
      "Epoch 21/250\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.5961 - accuracy: 0.6510\n",
      "Epoch 22/250\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5932 - accuracy: 0.6510\n",
      "Epoch 23/250\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5937 - accuracy: 0.6510\n",
      "Epoch 24/250\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5986 - accuracy: 0.6510\n",
      "Epoch 25/250\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5943 - accuracy: 0.6510\n",
      "Epoch 26/250\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5986 - accuracy: 0.6510\n",
      "Epoch 27/250\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5949 - accuracy: 0.6510\n",
      "Epoch 28/250\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.5904 - accuracy: 0.6510\n",
      "Epoch 29/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5931 - accuracy: 0.6510\n",
      "Epoch 30/250\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5912 - accuracy: 0.6510\n",
      "Epoch 31/250\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.5898 - accuracy: 0.6510\n",
      "Epoch 32/250\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5892 - accuracy: 0.6510\n",
      "Epoch 33/250\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5846 - accuracy: 0.6510\n",
      "Epoch 34/250\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5899 - accuracy: 0.6510\n",
      "Epoch 35/250\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5893 - accuracy: 0.6510\n",
      "Epoch 36/250\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5813 - accuracy: 0.6953\n",
      "Epoch 37/250\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5771 - accuracy: 0.6966\n",
      "Epoch 38/250\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5861 - accuracy: 0.6966\n",
      "Epoch 39/250\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5779 - accuracy: 0.6927\n",
      "Epoch 40/250\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5782 - accuracy: 0.7031\n",
      "Epoch 41/250\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5716 - accuracy: 0.7044\n",
      "Epoch 42/250\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5693 - accuracy: 0.7044\n",
      "Epoch 43/250\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5662 - accuracy: 0.7096\n",
      "Epoch 44/250\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5711 - accuracy: 0.7135\n",
      "Epoch 45/250\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5661 - accuracy: 0.7201\n",
      "Epoch 46/250\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5635 - accuracy: 0.6966\n",
      "Epoch 47/250\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5595 - accuracy: 0.7201\n",
      "Epoch 48/250\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5578 - accuracy: 0.7135\n",
      "Epoch 49/250\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5553 - accuracy: 0.7174\n",
      "Epoch 50/250\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.5553 - accuracy: 0.7201\n",
      "Epoch 51/250\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5553 - accuracy: 0.7083\n",
      "Epoch 52/250\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5575 - accuracy: 0.7122\n",
      "Epoch 53/250\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5514 - accuracy: 0.7070\n",
      "Epoch 54/250\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5525 - accuracy: 0.7214\n",
      "Epoch 55/250\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5511 - accuracy: 0.7214\n",
      "Epoch 56/250\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.5494 - accuracy: 0.7174\n",
      "Epoch 57/250\n",
      "768/768 [==============================] - 0s 82us/step - loss: 0.5461 - accuracy: 0.7240\n",
      "Epoch 58/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.5471 - accuracy: 0.7096\n",
      "Epoch 59/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5396 - accuracy: 0.7266\n",
      "Epoch 60/250\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5441 - accuracy: 0.7148\n",
      "Epoch 61/250\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5381 - accuracy: 0.7188\n",
      "Epoch 62/250\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5433 - accuracy: 0.7188\n",
      "Epoch 63/250\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5442 - accuracy: 0.7188\n",
      "Epoch 64/250\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5434 - accuracy: 0.7148\n",
      "Epoch 65/250\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.5353 - accuracy: 0.7292\n",
      "Epoch 66/250\n",
      "768/768 [==============================] - 0s 84us/step - loss: 0.5346 - accuracy: 0.7214\n",
      "Epoch 67/250\n",
      "768/768 [==============================] - 0s 81us/step - loss: 0.5289 - accuracy: 0.7305\n",
      "Epoch 68/250\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5340 - accuracy: 0.7201\n",
      "Epoch 69/250\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5280 - accuracy: 0.7331\n",
      "Epoch 70/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5361 - accuracy: 0.7292\n",
      "Epoch 71/250\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5287 - accuracy: 0.7344\n",
      "Epoch 72/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5286 - accuracy: 0.7344\n",
      "Epoch 73/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5226 - accuracy: 0.7448\n",
      "Epoch 74/250\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.5284 - accuracy: 0.7148\n",
      "Epoch 75/250\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.5201 - accuracy: 0.7448\n",
      "Epoch 76/250\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.5218 - accuracy: 0.7422\n",
      "Epoch 77/250\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.5192 - accuracy: 0.7370\n",
      "Epoch 78/250\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.5151 - accuracy: 0.7422\n",
      "Epoch 79/250\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.5210 - accuracy: 0.7357\n",
      "Epoch 80/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 192us/step - loss: 0.5161 - accuracy: 0.7500\n",
      "Epoch 81/250\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.5124 - accuracy: 0.7448\n",
      "Epoch 82/250\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.5156 - accuracy: 0.7383\n",
      "Epoch 83/250\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.5098 - accuracy: 0.7370\n",
      "Epoch 84/250\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5079 - accuracy: 0.7604\n",
      "Epoch 85/250\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5148 - accuracy: 0.7539\n",
      "Epoch 86/250\n",
      "768/768 [==============================] - 0s 207us/step - loss: 0.5147 - accuracy: 0.7474\n",
      "Epoch 87/250\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5126 - accuracy: 0.7526\n",
      "Epoch 88/250\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5054 - accuracy: 0.7500\n",
      "Epoch 89/250\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5192 - accuracy: 0.7539\n",
      "Epoch 90/250\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.5026 - accuracy: 0.7604\n",
      "Epoch 91/250\n",
      "768/768 [==============================] - 0s 231us/step - loss: 0.5046 - accuracy: 0.7539\n",
      "Epoch 92/250\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5017 - accuracy: 0.7617\n",
      "Epoch 93/250\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5012 - accuracy: 0.7474\n",
      "Epoch 94/250\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.5013 - accuracy: 0.7591\n",
      "Epoch 95/250\n",
      "768/768 [==============================] - 0s 213us/step - loss: 0.4958 - accuracy: 0.7513\n",
      "Epoch 96/250\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.5049 - accuracy: 0.7721\n",
      "Epoch 97/250\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4966 - accuracy: 0.7721\n",
      "Epoch 98/250\n",
      "768/768 [==============================] - 0s 153us/step - loss: 0.4935 - accuracy: 0.7773\n",
      "Epoch 99/250\n",
      "768/768 [==============================] - 0s 210us/step - loss: 0.4897 - accuracy: 0.7695\n",
      "Epoch 100/250\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.4932 - accuracy: 0.7630\n",
      "Epoch 101/250\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.4925 - accuracy: 0.7682\n",
      "Epoch 102/250\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.4914 - accuracy: 0.7656\n",
      "Epoch 103/250\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5018 - accuracy: 0.7643\n",
      "Epoch 104/250\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.4947 - accuracy: 0.7760\n",
      "Epoch 105/250\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.5096 - accuracy: 0.7552\n",
      "Epoch 106/250\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4964 - accuracy: 0.7604\n",
      "Epoch 107/250\n",
      "768/768 [==============================] - 0s 153us/step - loss: 0.4900 - accuracy: 0.7695\n",
      "Epoch 108/250\n",
      "768/768 [==============================] - 0s 186us/step - loss: 0.4964 - accuracy: 0.7552\n",
      "Epoch 109/250\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.4885 - accuracy: 0.7682\n",
      "Epoch 110/250\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4912 - accuracy: 0.7721\n",
      "Epoch 111/250\n",
      "768/768 [==============================] - 0s 176us/step - loss: 0.4954 - accuracy: 0.7630\n",
      "Epoch 112/250\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4877 - accuracy: 0.7565\n",
      "Epoch 113/250\n",
      "768/768 [==============================] - 0s 213us/step - loss: 0.4868 - accuracy: 0.7604\n",
      "Epoch 114/250\n",
      "768/768 [==============================] - 0s 241us/step - loss: 0.4961 - accuracy: 0.7617\n",
      "Epoch 115/250\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.4868 - accuracy: 0.7734\n",
      "Epoch 116/250\n",
      "768/768 [==============================] - 0s 162us/step - loss: 0.4880 - accuracy: 0.7708\n",
      "Epoch 117/250\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.4857 - accuracy: 0.7760\n",
      "Epoch 118/250\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.4915 - accuracy: 0.7617\n",
      "Epoch 119/250\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.4797 - accuracy: 0.7747\n",
      "Epoch 120/250\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.4851 - accuracy: 0.7708\n",
      "Epoch 121/250\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4920 - accuracy: 0.7773\n",
      "Epoch 122/250\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.4892 - accuracy: 0.7786\n",
      "Epoch 123/250\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.4830 - accuracy: 0.7708\n",
      "Epoch 124/250\n",
      "768/768 [==============================] - 0s 228us/step - loss: 0.4754 - accuracy: 0.7865\n",
      "Epoch 125/250\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.4766 - accuracy: 0.7852\n",
      "Epoch 126/250\n",
      "768/768 [==============================] - 0s 150us/step - loss: 0.4770 - accuracy: 0.7682\n",
      "Epoch 127/250\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.4779 - accuracy: 0.7617\n",
      "Epoch 128/250\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.4735 - accuracy: 0.7721\n",
      "Epoch 129/250\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4813 - accuracy: 0.7773\n",
      "Epoch 130/250\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.4713 - accuracy: 0.7904\n",
      "Epoch 131/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4745 - accuracy: 0.7747\n",
      "Epoch 132/250\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4713 - accuracy: 0.7786\n",
      "Epoch 133/250\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4815 - accuracy: 0.7721\n",
      "Epoch 134/250\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4759 - accuracy: 0.7786\n",
      "Epoch 135/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4711 - accuracy: 0.7760\n",
      "Epoch 136/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4708 - accuracy: 0.7760\n",
      "Epoch 137/250\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4652 - accuracy: 0.7799\n",
      "Epoch 138/250\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4711 - accuracy: 0.7852\n",
      "Epoch 139/250\n",
      "768/768 [==============================] - 0s 170us/step - loss: 0.4624 - accuracy: 0.7878\n",
      "Epoch 140/250\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.4719 - accuracy: 0.7799\n",
      "Epoch 141/250\n",
      "768/768 [==============================] - 0s 141us/step - loss: 0.4724 - accuracy: 0.7773\n",
      "Epoch 142/250\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4800 - accuracy: 0.7643\n",
      "Epoch 143/250\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4696 - accuracy: 0.7786\n",
      "Epoch 144/250\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4703 - accuracy: 0.7669\n",
      "Epoch 145/250\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4703 - accuracy: 0.7786\n",
      "Epoch 146/250\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4670 - accuracy: 0.7839\n",
      "Epoch 147/250\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4696 - accuracy: 0.7669\n",
      "Epoch 148/250\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.4689 - accuracy: 0.7773\n",
      "Epoch 149/250\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4625 - accuracy: 0.7786\n",
      "Epoch 150/250\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.4609 - accuracy: 0.7760\n",
      "Epoch 151/250\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4615 - accuracy: 0.7865\n",
      "Epoch 152/250\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4543 - accuracy: 0.7878\n",
      "Epoch 153/250\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.4657 - accuracy: 0.7760\n",
      "Epoch 154/250\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4577 - accuracy: 0.7773\n",
      "Epoch 155/250\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4629 - accuracy: 0.7799\n",
      "Epoch 156/250\n",
      "768/768 [==============================] - 0s 162us/step - loss: 0.4580 - accuracy: 0.7826\n",
      "Epoch 157/250\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4617 - accuracy: 0.7747\n",
      "Epoch 158/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 175us/step - loss: 0.4652 - accuracy: 0.7852\n",
      "Epoch 159/250\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4558 - accuracy: 0.7852\n",
      "Epoch 160/250\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4602 - accuracy: 0.7865\n",
      "Epoch 161/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4526 - accuracy: 0.7930\n",
      "Epoch 162/250\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.4528 - accuracy: 0.7917\n",
      "Epoch 163/250\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.4606 - accuracy: 0.7852\n",
      "Epoch 164/250\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.4608 - accuracy: 0.7826\n",
      "Epoch 165/250\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.4563 - accuracy: 0.7760\n",
      "Epoch 166/250\n",
      "768/768 [==============================] - 0s 165us/step - loss: 0.4507 - accuracy: 0.7917\n",
      "Epoch 167/250\n",
      "768/768 [==============================] - 0s 167us/step - loss: 0.4496 - accuracy: 0.7786\n",
      "Epoch 168/250\n",
      "768/768 [==============================] - 0s 161us/step - loss: 0.4528 - accuracy: 0.7917\n",
      "Epoch 169/250\n",
      "768/768 [==============================] - 0s 161us/step - loss: 0.4474 - accuracy: 0.7839\n",
      "Epoch 170/250\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4513 - accuracy: 0.7943\n",
      "Epoch 171/250\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.4469 - accuracy: 0.7826\n",
      "Epoch 172/250\n",
      "768/768 [==============================] - 0s 222us/step - loss: 0.4492 - accuracy: 0.7878\n",
      "Epoch 173/250\n",
      "768/768 [==============================] - 0s 210us/step - loss: 0.4531 - accuracy: 0.7878\n",
      "Epoch 174/250\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.4519 - accuracy: 0.7852\n",
      "Epoch 175/250\n",
      "768/768 [==============================] - 0s 217us/step - loss: 0.4558 - accuracy: 0.7786\n",
      "Epoch 176/250\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.4489 - accuracy: 0.7852\n",
      "Epoch 177/250\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.4570 - accuracy: 0.7917\n",
      "Epoch 178/250\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.4482 - accuracy: 0.7812\n",
      "Epoch 179/250\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.4427 - accuracy: 0.7904\n",
      "Epoch 180/250\n",
      "768/768 [==============================] - 0s 215us/step - loss: 0.4508 - accuracy: 0.7917\n",
      "Epoch 181/250\n",
      "768/768 [==============================] - 0s 230us/step - loss: 0.4442 - accuracy: 0.7982\n",
      "Epoch 182/250\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.4527 - accuracy: 0.7839\n",
      "Epoch 183/250\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4504 - accuracy: 0.7917\n",
      "Epoch 184/250\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.4572 - accuracy: 0.7865\n",
      "Epoch 185/250\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.4481 - accuracy: 0.7917\n",
      "Epoch 186/250\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.4556 - accuracy: 0.7799\n",
      "Epoch 187/250\n",
      "768/768 [==============================] - 0s 187us/step - loss: 0.4478 - accuracy: 0.7969\n",
      "Epoch 188/250\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4622 - accuracy: 0.7734\n",
      "Epoch 189/250\n",
      "768/768 [==============================] - 0s 226us/step - loss: 0.4480 - accuracy: 0.7839\n",
      "Epoch 190/250\n",
      "768/768 [==============================] - 0s 239us/step - loss: 0.4483 - accuracy: 0.7852\n",
      "Epoch 191/250\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.4422 - accuracy: 0.7852\n",
      "Epoch 192/250\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.4533 - accuracy: 0.7969\n",
      "Epoch 193/250\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.4529 - accuracy: 0.7812\n",
      "Epoch 194/250\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4432 - accuracy: 0.7982\n",
      "Epoch 195/250\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4664 - accuracy: 0.7747\n",
      "Epoch 196/250\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.4434 - accuracy: 0.7865\n",
      "Epoch 197/250\n",
      "768/768 [==============================] - 0s 218us/step - loss: 0.4425 - accuracy: 0.7943\n",
      "Epoch 198/250\n",
      "768/768 [==============================] - 0s 232us/step - loss: 0.4476 - accuracy: 0.7812\n",
      "Epoch 199/250\n",
      "768/768 [==============================] - 0s 169us/step - loss: 0.4527 - accuracy: 0.7930\n",
      "Epoch 200/250\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4420 - accuracy: 0.8008\n",
      "Epoch 201/250\n",
      "768/768 [==============================] - 0s 208us/step - loss: 0.4458 - accuracy: 0.7891\n",
      "Epoch 202/250\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.4517 - accuracy: 0.7773\n",
      "Epoch 203/250\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4448 - accuracy: 0.7904\n",
      "Epoch 204/250\n",
      "768/768 [==============================] - 0s 206us/step - loss: 0.4432 - accuracy: 0.7904\n",
      "Epoch 205/250\n",
      "768/768 [==============================] - 0s 149us/step - loss: 0.4417 - accuracy: 0.7969\n",
      "Epoch 206/250\n",
      "768/768 [==============================] - 0s 160us/step - loss: 0.4436 - accuracy: 0.7969\n",
      "Epoch 207/250\n",
      "768/768 [==============================] - 0s 190us/step - loss: 0.4499 - accuracy: 0.7865\n",
      "Epoch 208/250\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.4388 - accuracy: 0.7995\n",
      "Epoch 209/250\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.4472 - accuracy: 0.7943\n",
      "Epoch 210/250\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4380 - accuracy: 0.7969\n",
      "Epoch 211/250\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4348 - accuracy: 0.7930\n",
      "Epoch 212/250\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4484 - accuracy: 0.7917\n",
      "Epoch 213/250\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4437 - accuracy: 0.7956\n",
      "Epoch 214/250\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4524 - accuracy: 0.7891\n",
      "Epoch 215/250\n",
      "768/768 [==============================] - 0s 174us/step - loss: 0.4430 - accuracy: 0.7930\n",
      "Epoch 216/250\n",
      "768/768 [==============================] - 0s 173us/step - loss: 0.4455 - accuracy: 0.7878\n",
      "Epoch 217/250\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4539 - accuracy: 0.7852\n",
      "Epoch 218/250\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4458 - accuracy: 0.7930\n",
      "Epoch 219/250\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4362 - accuracy: 0.7904\n",
      "Epoch 220/250\n",
      "768/768 [==============================] - 0s 135us/step - loss: 0.4470 - accuracy: 0.7930\n",
      "Epoch 221/250\n",
      "768/768 [==============================] - 0s 152us/step - loss: 0.4425 - accuracy: 0.7995\n",
      "Epoch 222/250\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.4461 - accuracy: 0.7917\n",
      "Epoch 223/250\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.4524 - accuracy: 0.7839\n",
      "Epoch 224/250\n",
      "768/768 [==============================] - 0s 211us/step - loss: 0.4394 - accuracy: 0.8008\n",
      "Epoch 225/250\n",
      "768/768 [==============================] - 0s 175us/step - loss: 0.4489 - accuracy: 0.7826\n",
      "Epoch 226/250\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4378 - accuracy: 0.7917\n",
      "Epoch 227/250\n",
      "768/768 [==============================] - 0s 82us/step - loss: 0.4464 - accuracy: 0.7826\n",
      "Epoch 228/250\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.4320 - accuracy: 0.8060\n",
      "Epoch 229/250\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.4415 - accuracy: 0.7943\n",
      "Epoch 230/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4431 - accuracy: 0.7839\n",
      "Epoch 231/250\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4397 - accuracy: 0.8047\n",
      "Epoch 232/250\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4386 - accuracy: 0.7799\n",
      "Epoch 233/250\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4379 - accuracy: 0.7826\n",
      "Epoch 234/250\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4557 - accuracy: 0.7786\n",
      "Epoch 235/250\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4361 - accuracy: 0.7943\n",
      "Epoch 236/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 87us/step - loss: 0.4316 - accuracy: 0.7969\n",
      "Epoch 237/250\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4387 - accuracy: 0.7799\n",
      "Epoch 238/250\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.4499 - accuracy: 0.7995\n",
      "Epoch 239/250\n",
      "768/768 [==============================] - 0s 150us/step - loss: 0.4400 - accuracy: 0.7904\n",
      "Epoch 240/250\n",
      "768/768 [==============================] - 0s 160us/step - loss: 0.4389 - accuracy: 0.7930\n",
      "Epoch 241/250\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.4445 - accuracy: 0.7891\n",
      "Epoch 242/250\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4370 - accuracy: 0.7969\n",
      "Epoch 243/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4313 - accuracy: 0.7982\n",
      "Epoch 244/250\n",
      "768/768 [==============================] - 0s 84us/step - loss: 0.4333 - accuracy: 0.7878\n",
      "Epoch 245/250\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4581 - accuracy: 0.7904\n",
      "Epoch 246/250\n",
      "768/768 [==============================] - 0s 79us/step - loss: 0.4397 - accuracy: 0.7891\n",
      "Epoch 247/250\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4398 - accuracy: 0.7943\n",
      "Epoch 248/250\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4424 - accuracy: 0.7852\n",
      "Epoch 249/250\n",
      "768/768 [==============================] - 0s 157us/step - loss: 0.4368 - accuracy: 0.7969\n",
      "Epoch 250/250\n",
      "768/768 [==============================] - 0s 156us/step - loss: 0.4489 - accuracy: 0.7865\n",
      "768/768 [==============================] - 0s 131us/step\n",
      "accuracy: 79.95%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, Y, epochs=250, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1],scores[1]*100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/250\n",
      "514/514 [==============================] - 0s 461us/step - loss: 0.6796 - accuracy: 0.6401 - val_loss: 0.6586 - val_accuracy: 0.6732\n",
      "Epoch 2/250\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.6688 - accuracy: 0.6401 - val_loss: 0.6533 - val_accuracy: 0.6732\n",
      "Epoch 3/250\n",
      "514/514 [==============================] - 0s 123us/step - loss: 0.6617 - accuracy: 0.6381 - val_loss: 0.6511 - val_accuracy: 0.6732\n",
      "Epoch 4/250\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.6546 - accuracy: 0.6401 - val_loss: 0.6458 - val_accuracy: 0.6890\n",
      "Epoch 5/250\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.6456 - accuracy: 0.6440 - val_loss: 0.6363 - val_accuracy: 0.7047\n",
      "Epoch 6/250\n",
      "514/514 [==============================] - 0s 233us/step - loss: 0.6391 - accuracy: 0.6498 - val_loss: 0.6232 - val_accuracy: 0.6890\n",
      "Epoch 7/250\n",
      "514/514 [==============================] - 0s 132us/step - loss: 0.6333 - accuracy: 0.6556 - val_loss: 0.6154 - val_accuracy: 0.6890\n",
      "Epoch 8/250\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.6216 - accuracy: 0.6673 - val_loss: 0.6033 - val_accuracy: 0.6811\n",
      "Epoch 9/250\n",
      "514/514 [==============================] - 0s 132us/step - loss: 0.6178 - accuracy: 0.6615 - val_loss: 0.6049 - val_accuracy: 0.6929\n",
      "Epoch 10/250\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.6101 - accuracy: 0.6965 - val_loss: 0.5952 - val_accuracy: 0.7126\n",
      "Epoch 11/250\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.6044 - accuracy: 0.6809 - val_loss: 0.5964 - val_accuracy: 0.6811\n",
      "Epoch 12/250\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.6061 - accuracy: 0.6868 - val_loss: 0.5785 - val_accuracy: 0.7126\n",
      "Epoch 13/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.6025 - accuracy: 0.6984 - val_loss: 0.5830 - val_accuracy: 0.6929\n",
      "Epoch 14/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.5892 - accuracy: 0.7121 - val_loss: 0.5714 - val_accuracy: 0.7087\n",
      "Epoch 15/250\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.5860 - accuracy: 0.7198 - val_loss: 0.5736 - val_accuracy: 0.7087\n",
      "Epoch 16/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.5934 - accuracy: 0.7004 - val_loss: 0.5699 - val_accuracy: 0.7087\n",
      "Epoch 17/250\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.5850 - accuracy: 0.7101 - val_loss: 0.5667 - val_accuracy: 0.7126\n",
      "Epoch 18/250\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.5813 - accuracy: 0.7160 - val_loss: 0.5715 - val_accuracy: 0.7165\n",
      "Epoch 19/250\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.5795 - accuracy: 0.7023 - val_loss: 0.5707 - val_accuracy: 0.7087\n",
      "Epoch 20/250\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5761 - accuracy: 0.7140 - val_loss: 0.5676 - val_accuracy: 0.7205\n",
      "Epoch 21/250\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.5756 - accuracy: 0.7062 - val_loss: 0.5720 - val_accuracy: 0.7165\n",
      "Epoch 22/250\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.5718 - accuracy: 0.7335 - val_loss: 0.5630 - val_accuracy: 0.7047\n",
      "Epoch 23/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.5729 - accuracy: 0.7043 - val_loss: 0.5657 - val_accuracy: 0.7165\n",
      "Epoch 24/250\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.5583 - accuracy: 0.7374 - val_loss: 0.5596 - val_accuracy: 0.7283\n",
      "Epoch 25/250\n",
      "514/514 [==============================] - 0s 118us/step - loss: 0.5646 - accuracy: 0.7198 - val_loss: 0.5564 - val_accuracy: 0.7126\n",
      "Epoch 26/250\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.5611 - accuracy: 0.7354 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
      "Epoch 27/250\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.5584 - accuracy: 0.7412 - val_loss: 0.5635 - val_accuracy: 0.7205\n",
      "Epoch 28/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.5569 - accuracy: 0.7218 - val_loss: 0.6370 - val_accuracy: 0.5906\n",
      "Epoch 29/250\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5569 - accuracy: 0.7218 - val_loss: 0.5794 - val_accuracy: 0.7205\n",
      "Epoch 30/250\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.5534 - accuracy: 0.7237 - val_loss: 0.5679 - val_accuracy: 0.7283\n",
      "Epoch 31/250\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5463 - accuracy: 0.7179 - val_loss: 0.5742 - val_accuracy: 0.7283\n",
      "Epoch 32/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.5596 - accuracy: 0.7335 - val_loss: 0.5946 - val_accuracy: 0.6654\n",
      "Epoch 33/250\n",
      "514/514 [==============================] - 0s 126us/step - loss: 0.5746 - accuracy: 0.7237 - val_loss: 0.5873 - val_accuracy: 0.7244\n",
      "Epoch 34/250\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.5498 - accuracy: 0.7315 - val_loss: 0.5683 - val_accuracy: 0.7087\n",
      "Epoch 35/250\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.5442 - accuracy: 0.7237 - val_loss: 0.5556 - val_accuracy: 0.7283\n",
      "Epoch 36/250\n",
      "514/514 [==============================] - 0s 275us/step - loss: 0.5515 - accuracy: 0.7237 - val_loss: 0.5668 - val_accuracy: 0.7087\n",
      "Epoch 37/250\n",
      "514/514 [==============================] - 0s 230us/step - loss: 0.5449 - accuracy: 0.7315 - val_loss: 0.5664 - val_accuracy: 0.7362\n",
      "Epoch 38/250\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.5451 - accuracy: 0.7374 - val_loss: 0.5489 - val_accuracy: 0.7441\n",
      "Epoch 39/250\n",
      "514/514 [==============================] - 0s 197us/step - loss: 0.5497 - accuracy: 0.7160 - val_loss: 0.5567 - val_accuracy: 0.7480\n",
      "Epoch 40/250\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.5439 - accuracy: 0.7354 - val_loss: 0.5501 - val_accuracy: 0.7244\n",
      "Epoch 41/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.5390 - accuracy: 0.7412 - val_loss: 0.5498 - val_accuracy: 0.7323\n",
      "Epoch 42/250\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.5459 - accuracy: 0.7432 - val_loss: 0.5827 - val_accuracy: 0.7165\n",
      "Epoch 43/250\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5444 - accuracy: 0.7354 - val_loss: 0.5581 - val_accuracy: 0.7402\n",
      "Epoch 44/250\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.5427 - accuracy: 0.7198 - val_loss: 0.5521 - val_accuracy: 0.7323\n",
      "Epoch 45/250\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.5363 - accuracy: 0.7276 - val_loss: 0.5820 - val_accuracy: 0.6772\n",
      "Epoch 46/250\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.5470 - accuracy: 0.7160 - val_loss: 0.5651 - val_accuracy: 0.7244\n",
      "Epoch 47/250\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.5501 - accuracy: 0.7374 - val_loss: 0.5509 - val_accuracy: 0.7402\n",
      "Epoch 48/250\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.5385 - accuracy: 0.7257 - val_loss: 0.5572 - val_accuracy: 0.7402\n",
      "Epoch 49/250\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5380 - accuracy: 0.7451 - val_loss: 0.5499 - val_accuracy: 0.7323\n",
      "Epoch 50/250\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.5359 - accuracy: 0.7374 - val_loss: 0.5690 - val_accuracy: 0.6929\n",
      "Epoch 51/250\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.5302 - accuracy: 0.7451 - val_loss: 0.5528 - val_accuracy: 0.7402\n",
      "Epoch 52/250\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.5374 - accuracy: 0.7432 - val_loss: 0.5573 - val_accuracy: 0.7205\n",
      "Epoch 53/250\n",
      "514/514 [==============================] - 0s 131us/step - loss: 0.5325 - accuracy: 0.7490 - val_loss: 0.5429 - val_accuracy: 0.7402\n",
      "Epoch 54/250\n",
      "514/514 [==============================] - 0s 228us/step - loss: 0.5296 - accuracy: 0.7374 - val_loss: 0.5505 - val_accuracy: 0.7402\n",
      "Epoch 55/250\n",
      "514/514 [==============================] - 0s 275us/step - loss: 0.5281 - accuracy: 0.7393 - val_loss: 0.5579 - val_accuracy: 0.7205\n",
      "Epoch 56/250\n",
      "514/514 [==============================] - 0s 263us/step - loss: 0.5387 - accuracy: 0.7374 - val_loss: 0.5610 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/250\n",
      "514/514 [==============================] - 0s 268us/step - loss: 0.5385 - accuracy: 0.7393 - val_loss: 0.5686 - val_accuracy: 0.7283\n",
      "Epoch 58/250\n",
      "514/514 [==============================] - 0s 283us/step - loss: 0.5285 - accuracy: 0.7335 - val_loss: 0.5613 - val_accuracy: 0.7087\n",
      "Epoch 59/250\n",
      "514/514 [==============================] - 0s 249us/step - loss: 0.5414 - accuracy: 0.7257 - val_loss: 0.5506 - val_accuracy: 0.7441\n",
      "Epoch 60/250\n",
      "514/514 [==============================] - 0s 228us/step - loss: 0.5335 - accuracy: 0.7315 - val_loss: 0.5544 - val_accuracy: 0.7362\n",
      "Epoch 61/250\n",
      "514/514 [==============================] - 0s 229us/step - loss: 0.5323 - accuracy: 0.7432 - val_loss: 0.5634 - val_accuracy: 0.7283\n",
      "Epoch 62/250\n",
      "514/514 [==============================] - 0s 210us/step - loss: 0.5346 - accuracy: 0.7315 - val_loss: 0.5485 - val_accuracy: 0.7402\n",
      "Epoch 63/250\n",
      "514/514 [==============================] - 0s 217us/step - loss: 0.5261 - accuracy: 0.7354 - val_loss: 0.5470 - val_accuracy: 0.7441\n",
      "Epoch 64/250\n",
      "514/514 [==============================] - 0s 208us/step - loss: 0.5300 - accuracy: 0.7432 - val_loss: 0.5520 - val_accuracy: 0.7362\n",
      "Epoch 65/250\n",
      "514/514 [==============================] - 0s 223us/step - loss: 0.5344 - accuracy: 0.7276 - val_loss: 0.5586 - val_accuracy: 0.7283\n",
      "Epoch 66/250\n",
      "514/514 [==============================] - 0s 285us/step - loss: 0.5316 - accuracy: 0.7276 - val_loss: 0.5382 - val_accuracy: 0.7598\n",
      "Epoch 67/250\n",
      "514/514 [==============================] - 0s 308us/step - loss: 0.5265 - accuracy: 0.7374 - val_loss: 0.5566 - val_accuracy: 0.7283\n",
      "Epoch 68/250\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.5326 - accuracy: 0.7335 - val_loss: 0.5636 - val_accuracy: 0.7323\n",
      "Epoch 69/250\n",
      "514/514 [==============================] - 0s 235us/step - loss: 0.5300 - accuracy: 0.7296 - val_loss: 0.5498 - val_accuracy: 0.7520\n",
      "Epoch 70/250\n",
      "514/514 [==============================] - 0s 255us/step - loss: 0.5311 - accuracy: 0.7529 - val_loss: 0.5409 - val_accuracy: 0.7323\n",
      "Epoch 71/250\n",
      "514/514 [==============================] - 0s 250us/step - loss: 0.5246 - accuracy: 0.7471 - val_loss: 0.5512 - val_accuracy: 0.7480\n",
      "Epoch 72/250\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.5256 - accuracy: 0.7471 - val_loss: 0.5334 - val_accuracy: 0.7756\n",
      "Epoch 73/250\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.5278 - accuracy: 0.7393 - val_loss: 0.5367 - val_accuracy: 0.7480\n",
      "Epoch 74/250\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.5228 - accuracy: 0.7374 - val_loss: 0.5417 - val_accuracy: 0.7598\n",
      "Epoch 75/250\n",
      "514/514 [==============================] - 0s 270us/step - loss: 0.5251 - accuracy: 0.7451 - val_loss: 0.5400 - val_accuracy: 0.7559\n",
      "Epoch 76/250\n",
      "514/514 [==============================] - 0s 255us/step - loss: 0.5197 - accuracy: 0.7529 - val_loss: 0.5364 - val_accuracy: 0.7441\n",
      "Epoch 77/250\n",
      "514/514 [==============================] - 0s 121us/step - loss: 0.5199 - accuracy: 0.7393 - val_loss: 0.5389 - val_accuracy: 0.7520\n",
      "Epoch 78/250\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5178 - accuracy: 0.7412 - val_loss: 0.5342 - val_accuracy: 0.7677\n",
      "Epoch 79/250\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5295 - accuracy: 0.7393 - val_loss: 0.5497 - val_accuracy: 0.7480\n",
      "Epoch 80/250\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5213 - accuracy: 0.7412 - val_loss: 0.5379 - val_accuracy: 0.7598\n",
      "Epoch 81/250\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.5289 - accuracy: 0.7549 - val_loss: 0.5401 - val_accuracy: 0.7480\n",
      "Epoch 82/250\n",
      "514/514 [==============================] - 0s 207us/step - loss: 0.5210 - accuracy: 0.7276 - val_loss: 0.5296 - val_accuracy: 0.7756\n",
      "Epoch 83/250\n",
      "514/514 [==============================] - 0s 260us/step - loss: 0.5145 - accuracy: 0.7276 - val_loss: 0.5458 - val_accuracy: 0.7283\n",
      "Epoch 84/250\n",
      "514/514 [==============================] - 0s 216us/step - loss: 0.5262 - accuracy: 0.7490 - val_loss: 0.5301 - val_accuracy: 0.7756\n",
      "Epoch 85/250\n",
      "514/514 [==============================] - 0s 135us/step - loss: 0.5193 - accuracy: 0.7529 - val_loss: 0.5366 - val_accuracy: 0.7362\n",
      "Epoch 86/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.5159 - accuracy: 0.7315 - val_loss: 0.5372 - val_accuracy: 0.7598\n",
      "Epoch 87/250\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.5152 - accuracy: 0.7432 - val_loss: 0.5288 - val_accuracy: 0.7717\n",
      "Epoch 88/250\n",
      "514/514 [==============================] - 0s 235us/step - loss: 0.5140 - accuracy: 0.7510 - val_loss: 0.5373 - val_accuracy: 0.7402\n",
      "Epoch 89/250\n",
      "514/514 [==============================] - 0s 285us/step - loss: 0.5143 - accuracy: 0.7510 - val_loss: 0.5307 - val_accuracy: 0.7638\n",
      "Epoch 90/250\n",
      "514/514 [==============================] - 0s 196us/step - loss: 0.5162 - accuracy: 0.7412 - val_loss: 0.5379 - val_accuracy: 0.7402\n",
      "Epoch 91/250\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.5168 - accuracy: 0.7432 - val_loss: 0.5399 - val_accuracy: 0.7441\n",
      "Epoch 92/250\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.5237 - accuracy: 0.7374 - val_loss: 0.5404 - val_accuracy: 0.7323\n",
      "Epoch 93/250\n",
      "514/514 [==============================] - 0s 215us/step - loss: 0.5146 - accuracy: 0.7510 - val_loss: 0.5364 - val_accuracy: 0.7559\n",
      "Epoch 94/250\n",
      "514/514 [==============================] - 0s 306us/step - loss: 0.5134 - accuracy: 0.7490 - val_loss: 0.5272 - val_accuracy: 0.7638\n",
      "Epoch 95/250\n",
      "514/514 [==============================] - 0s 199us/step - loss: 0.5162 - accuracy: 0.7490 - val_loss: 0.5422 - val_accuracy: 0.7244\n",
      "Epoch 96/250\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.5202 - accuracy: 0.7374 - val_loss: 0.5262 - val_accuracy: 0.7795\n",
      "Epoch 97/250\n",
      "514/514 [==============================] - 0s 313us/step - loss: 0.5144 - accuracy: 0.7510 - val_loss: 0.5207 - val_accuracy: 0.7677\n",
      "Epoch 98/250\n",
      "514/514 [==============================] - 0s 302us/step - loss: 0.5203 - accuracy: 0.7354 - val_loss: 0.5402 - val_accuracy: 0.7441\n",
      "Epoch 99/250\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5224 - accuracy: 0.7315 - val_loss: 0.5295 - val_accuracy: 0.7717\n",
      "Epoch 100/250\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5135 - accuracy: 0.7393 - val_loss: 0.5200 - val_accuracy: 0.7756\n",
      "Epoch 101/250\n",
      "514/514 [==============================] - 0s 360us/step - loss: 0.5126 - accuracy: 0.7471 - val_loss: 0.5274 - val_accuracy: 0.7717\n",
      "Epoch 102/250\n",
      "514/514 [==============================] - 0s 277us/step - loss: 0.5062 - accuracy: 0.7529 - val_loss: 0.5158 - val_accuracy: 0.7913\n",
      "Epoch 103/250\n",
      "514/514 [==============================] - 0s 230us/step - loss: 0.5172 - accuracy: 0.7451 - val_loss: 0.5260 - val_accuracy: 0.7480\n",
      "Epoch 104/250\n",
      "514/514 [==============================] - 0s 354us/step - loss: 0.5121 - accuracy: 0.7432 - val_loss: 0.5190 - val_accuracy: 0.7795\n",
      "Epoch 105/250\n",
      "514/514 [==============================] - 0s 326us/step - loss: 0.5034 - accuracy: 0.7490 - val_loss: 0.5274 - val_accuracy: 0.7638\n",
      "Epoch 106/250\n",
      "514/514 [==============================] - 0s 274us/step - loss: 0.5113 - accuracy: 0.7451 - val_loss: 0.5191 - val_accuracy: 0.7598\n",
      "Epoch 107/250\n",
      "514/514 [==============================] - 0s 365us/step - loss: 0.5118 - accuracy: 0.7432 - val_loss: 0.5374 - val_accuracy: 0.7362\n",
      "Epoch 108/250\n",
      "514/514 [==============================] - 0s 247us/step - loss: 0.5169 - accuracy: 0.7549 - val_loss: 0.5281 - val_accuracy: 0.7480\n",
      "Epoch 109/250\n",
      "514/514 [==============================] - 0s 314us/step - loss: 0.5088 - accuracy: 0.7510 - val_loss: 0.5185 - val_accuracy: 0.7874\n",
      "Epoch 110/250\n",
      "514/514 [==============================] - 0s 336us/step - loss: 0.4996 - accuracy: 0.7471 - val_loss: 0.5555 - val_accuracy: 0.7362\n",
      "Epoch 111/250\n",
      "514/514 [==============================] - 0s 277us/step - loss: 0.5162 - accuracy: 0.7393 - val_loss: 0.5289 - val_accuracy: 0.7598\n",
      "Epoch 112/250\n",
      "514/514 [==============================] - 0s 271us/step - loss: 0.5044 - accuracy: 0.7490 - val_loss: 0.5319 - val_accuracy: 0.7480\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 315us/step - loss: 0.5053 - accuracy: 0.7510 - val_loss: 0.5188 - val_accuracy: 0.7598\n",
      "Epoch 114/250\n",
      "514/514 [==============================] - 0s 343us/step - loss: 0.5010 - accuracy: 0.7374 - val_loss: 0.5151 - val_accuracy: 0.7756\n",
      "Epoch 115/250\n",
      "514/514 [==============================] - 0s 255us/step - loss: 0.5014 - accuracy: 0.7471 - val_loss: 0.5145 - val_accuracy: 0.7756\n",
      "Epoch 116/250\n",
      "514/514 [==============================] - 0s 347us/step - loss: 0.5038 - accuracy: 0.7471 - val_loss: 0.5134 - val_accuracy: 0.7953\n",
      "Epoch 117/250\n",
      "514/514 [==============================] - 0s 242us/step - loss: 0.5062 - accuracy: 0.7529 - val_loss: 0.5449 - val_accuracy: 0.7441\n",
      "Epoch 118/250\n",
      "514/514 [==============================] - 0s 210us/step - loss: 0.4995 - accuracy: 0.7393 - val_loss: 0.5192 - val_accuracy: 0.7598\n",
      "Epoch 119/250\n",
      "514/514 [==============================] - 0s 221us/step - loss: 0.5077 - accuracy: 0.7471 - val_loss: 0.5236 - val_accuracy: 0.7835\n",
      "Epoch 120/250\n",
      "514/514 [==============================] - 0s 333us/step - loss: 0.4976 - accuracy: 0.7490 - val_loss: 0.5125 - val_accuracy: 0.7638\n",
      "Epoch 121/250\n",
      "514/514 [==============================] - 0s 252us/step - loss: 0.5024 - accuracy: 0.7529 - val_loss: 0.5231 - val_accuracy: 0.7638\n",
      "Epoch 122/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.4995 - accuracy: 0.7607 - val_loss: 0.5130 - val_accuracy: 0.7835\n",
      "Epoch 123/250\n",
      "514/514 [==============================] - 0s 299us/step - loss: 0.4992 - accuracy: 0.7490 - val_loss: 0.5282 - val_accuracy: 0.7480\n",
      "Epoch 124/250\n",
      "514/514 [==============================] - 0s 374us/step - loss: 0.4969 - accuracy: 0.7549 - val_loss: 0.5312 - val_accuracy: 0.7559\n",
      "Epoch 125/250\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.5033 - accuracy: 0.7471 - val_loss: 0.5186 - val_accuracy: 0.7598\n",
      "Epoch 126/250\n",
      "514/514 [==============================] - 0s 247us/step - loss: 0.4890 - accuracy: 0.7490 - val_loss: 0.5288 - val_accuracy: 0.7638\n",
      "Epoch 127/250\n",
      "514/514 [==============================] - 0s 311us/step - loss: 0.4909 - accuracy: 0.7529 - val_loss: 0.5157 - val_accuracy: 0.7598\n",
      "Epoch 128/250\n",
      "514/514 [==============================] - 0s 223us/step - loss: 0.4950 - accuracy: 0.7626 - val_loss: 0.5207 - val_accuracy: 0.7559\n",
      "Epoch 129/250\n",
      "514/514 [==============================] - 0s 249us/step - loss: 0.5003 - accuracy: 0.7432 - val_loss: 0.5078 - val_accuracy: 0.7795\n",
      "Epoch 130/250\n",
      "514/514 [==============================] - 0s 362us/step - loss: 0.4934 - accuracy: 0.7471 - val_loss: 0.5122 - val_accuracy: 0.7756\n",
      "Epoch 131/250\n",
      "514/514 [==============================] - 0s 266us/step - loss: 0.4904 - accuracy: 0.7588 - val_loss: 0.5202 - val_accuracy: 0.7283\n",
      "Epoch 132/250\n",
      "514/514 [==============================] - 0s 372us/step - loss: 0.4940 - accuracy: 0.7549 - val_loss: 0.5183 - val_accuracy: 0.7638\n",
      "Epoch 133/250\n",
      "514/514 [==============================] - 0s 281us/step - loss: 0.4930 - accuracy: 0.7607 - val_loss: 0.5203 - val_accuracy: 0.7717\n",
      "Epoch 134/250\n",
      "514/514 [==============================] - 0s 296us/step - loss: 0.4887 - accuracy: 0.7568 - val_loss: 0.5164 - val_accuracy: 0.7520\n",
      "Epoch 135/250\n",
      "514/514 [==============================] - 0s 339us/step - loss: 0.4858 - accuracy: 0.7471 - val_loss: 0.5085 - val_accuracy: 0.7913\n",
      "Epoch 136/250\n",
      "514/514 [==============================] - 0s 294us/step - loss: 0.4897 - accuracy: 0.7451 - val_loss: 0.5129 - val_accuracy: 0.7677\n",
      "Epoch 137/250\n",
      "514/514 [==============================] - 0s 335us/step - loss: 0.5050 - accuracy: 0.7354 - val_loss: 0.5148 - val_accuracy: 0.7717\n",
      "Epoch 138/250\n",
      "514/514 [==============================] - 0s 244us/step - loss: 0.4882 - accuracy: 0.7510 - val_loss: 0.5146 - val_accuracy: 0.7677\n",
      "Epoch 139/250\n",
      "514/514 [==============================] - 0s 224us/step - loss: 0.4941 - accuracy: 0.7490 - val_loss: 0.5081 - val_accuracy: 0.7795\n",
      "Epoch 140/250\n",
      "514/514 [==============================] - 0s 329us/step - loss: 0.4818 - accuracy: 0.7626 - val_loss: 0.5138 - val_accuracy: 0.7795\n",
      "Epoch 141/250\n",
      "514/514 [==============================] - 0s 322us/step - loss: 0.4860 - accuracy: 0.7432 - val_loss: 0.5015 - val_accuracy: 0.7953\n",
      "Epoch 142/250\n",
      "514/514 [==============================] - 0s 251us/step - loss: 0.4849 - accuracy: 0.7549 - val_loss: 0.5062 - val_accuracy: 0.7795\n",
      "Epoch 143/250\n",
      "514/514 [==============================] - 0s 361us/step - loss: 0.4898 - accuracy: 0.7510 - val_loss: 0.5046 - val_accuracy: 0.7835\n",
      "Epoch 144/250\n",
      "514/514 [==============================] - 0s 254us/step - loss: 0.4946 - accuracy: 0.7451 - val_loss: 0.5142 - val_accuracy: 0.7795\n",
      "Epoch 145/250\n",
      "514/514 [==============================] - 0s 284us/step - loss: 0.4846 - accuracy: 0.7490 - val_loss: 0.5084 - val_accuracy: 0.7913\n",
      "Epoch 146/250\n",
      "514/514 [==============================] - 0s 330us/step - loss: 0.4841 - accuracy: 0.7549 - val_loss: 0.5205 - val_accuracy: 0.7795\n",
      "Epoch 147/250\n",
      "514/514 [==============================] - 0s 240us/step - loss: 0.4813 - accuracy: 0.7451 - val_loss: 0.5121 - val_accuracy: 0.7795\n",
      "Epoch 148/250\n",
      "514/514 [==============================] - 0s 294us/step - loss: 0.4875 - accuracy: 0.7626 - val_loss: 0.5230 - val_accuracy: 0.7756\n",
      "Epoch 149/250\n",
      "514/514 [==============================] - 0s 340us/step - loss: 0.4788 - accuracy: 0.7588 - val_loss: 0.5140 - val_accuracy: 0.7835\n",
      "Epoch 150/250\n",
      "514/514 [==============================] - 0s 232us/step - loss: 0.4847 - accuracy: 0.7665 - val_loss: 0.5152 - val_accuracy: 0.7598\n",
      "Epoch 151/250\n",
      "514/514 [==============================] - 0s 281us/step - loss: 0.4840 - accuracy: 0.7529 - val_loss: 0.5047 - val_accuracy: 0.7874\n",
      "Epoch 152/250\n",
      "514/514 [==============================] - 0s 345us/step - loss: 0.4846 - accuracy: 0.7568 - val_loss: 0.5128 - val_accuracy: 0.7795\n",
      "Epoch 153/250\n",
      "514/514 [==============================] - 0s 233us/step - loss: 0.4892 - accuracy: 0.7451 - val_loss: 0.5089 - val_accuracy: 0.7717\n",
      "Epoch 154/250\n",
      "514/514 [==============================] - 0s 332us/step - loss: 0.4813 - accuracy: 0.7607 - val_loss: 0.5069 - val_accuracy: 0.7756\n",
      "Epoch 155/250\n",
      "514/514 [==============================] - 0s 334us/step - loss: 0.4795 - accuracy: 0.7646 - val_loss: 0.5407 - val_accuracy: 0.7559\n",
      "Epoch 156/250\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.4808 - accuracy: 0.7588 - val_loss: 0.5099 - val_accuracy: 0.7677\n",
      "Epoch 157/250\n",
      "514/514 [==============================] - 0s 314us/step - loss: 0.4899 - accuracy: 0.7626 - val_loss: 0.5076 - val_accuracy: 0.7835\n",
      "Epoch 158/250\n",
      "514/514 [==============================] - 0s 343us/step - loss: 0.4846 - accuracy: 0.7626 - val_loss: 0.5023 - val_accuracy: 0.7835\n",
      "Epoch 159/250\n",
      "514/514 [==============================] - 0s 266us/step - loss: 0.4776 - accuracy: 0.7568 - val_loss: 0.5122 - val_accuracy: 0.7874\n",
      "Epoch 160/250\n",
      "514/514 [==============================] - 0s 339us/step - loss: 0.4740 - accuracy: 0.7646 - val_loss: 0.5099 - val_accuracy: 0.7717\n",
      "Epoch 161/250\n",
      "514/514 [==============================] - 0s 238us/step - loss: 0.4781 - accuracy: 0.7588 - val_loss: 0.5079 - val_accuracy: 0.7795\n",
      "Epoch 162/250\n",
      "514/514 [==============================] - 0s 232us/step - loss: 0.4766 - accuracy: 0.7724 - val_loss: 0.5052 - val_accuracy: 0.7913\n",
      "Epoch 163/250\n",
      "514/514 [==============================] - 0s 352us/step - loss: 0.4852 - accuracy: 0.7646 - val_loss: 0.5280 - val_accuracy: 0.7362\n",
      "Epoch 164/250\n",
      "514/514 [==============================] - 0s 242us/step - loss: 0.4814 - accuracy: 0.7568 - val_loss: 0.5100 - val_accuracy: 0.7874\n",
      "Epoch 165/250\n",
      "514/514 [==============================] - 0s 232us/step - loss: 0.4725 - accuracy: 0.7704 - val_loss: 0.5022 - val_accuracy: 0.7953\n",
      "Epoch 166/250\n",
      "514/514 [==============================] - 0s 289us/step - loss: 0.4788 - accuracy: 0.7607 - val_loss: 0.5118 - val_accuracy: 0.7638\n",
      "Epoch 167/250\n",
      "514/514 [==============================] - 0s 277us/step - loss: 0.4914 - accuracy: 0.7412 - val_loss: 0.5076 - val_accuracy: 0.7835\n",
      "Epoch 168/250\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.4724 - accuracy: 0.7626 - val_loss: 0.5032 - val_accuracy: 0.7913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "514/514 [==============================] - 0s 250us/step - loss: 0.4742 - accuracy: 0.7549 - val_loss: 0.5092 - val_accuracy: 0.7677\n",
      "Epoch 170/250\n",
      "514/514 [==============================] - 0s 344us/step - loss: 0.4785 - accuracy: 0.7451 - val_loss: 0.5208 - val_accuracy: 0.7677\n",
      "Epoch 171/250\n",
      "514/514 [==============================] - 0s 223us/step - loss: 0.4761 - accuracy: 0.7568 - val_loss: 0.5067 - val_accuracy: 0.7756\n",
      "Epoch 172/250\n",
      "514/514 [==============================] - 0s 115us/step - loss: 0.4697 - accuracy: 0.7782 - val_loss: 0.5051 - val_accuracy: 0.7677\n",
      "Epoch 173/250\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.4941 - accuracy: 0.7549 - val_loss: 0.5008 - val_accuracy: 0.7874\n",
      "Epoch 174/250\n",
      "514/514 [==============================] - 0s 309us/step - loss: 0.4715 - accuracy: 0.7685 - val_loss: 0.4988 - val_accuracy: 0.7756\n",
      "Epoch 175/250\n",
      "514/514 [==============================] - 0s 253us/step - loss: 0.4694 - accuracy: 0.7646 - val_loss: 0.5037 - val_accuracy: 0.7913\n",
      "Epoch 176/250\n",
      "514/514 [==============================] - 0s 146us/step - loss: 0.4712 - accuracy: 0.7665 - val_loss: 0.5034 - val_accuracy: 0.7835\n",
      "Epoch 177/250\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.4738 - accuracy: 0.7646 - val_loss: 0.5170 - val_accuracy: 0.7835\n",
      "Epoch 178/250\n",
      "514/514 [==============================] - 0s 228us/step - loss: 0.4770 - accuracy: 0.7588 - val_loss: 0.5051 - val_accuracy: 0.7677\n",
      "Epoch 179/250\n",
      "514/514 [==============================] - 0s 273us/step - loss: 0.4678 - accuracy: 0.7724 - val_loss: 0.4996 - val_accuracy: 0.7795\n",
      "Epoch 180/250\n",
      "514/514 [==============================] - 0s 326us/step - loss: 0.4752 - accuracy: 0.7568 - val_loss: 0.4978 - val_accuracy: 0.7756\n",
      "Epoch 181/250\n",
      "514/514 [==============================] - 0s 265us/step - loss: 0.4644 - accuracy: 0.7607 - val_loss: 0.5090 - val_accuracy: 0.7835\n",
      "Epoch 182/250\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.4867 - accuracy: 0.7490 - val_loss: 0.5056 - val_accuracy: 0.7913\n",
      "Epoch 183/250\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4740 - accuracy: 0.7529 - val_loss: 0.5081 - val_accuracy: 0.7874\n",
      "Epoch 184/250\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.4698 - accuracy: 0.7607 - val_loss: 0.4959 - val_accuracy: 0.7717\n",
      "Epoch 185/250\n",
      "514/514 [==============================] - 0s 228us/step - loss: 0.4638 - accuracy: 0.7704 - val_loss: 0.5076 - val_accuracy: 0.7717\n",
      "Epoch 186/250\n",
      "514/514 [==============================] - 0s 318us/step - loss: 0.4635 - accuracy: 0.7685 - val_loss: 0.5102 - val_accuracy: 0.7795\n",
      "Epoch 187/250\n",
      "514/514 [==============================] - 0s 359us/step - loss: 0.4711 - accuracy: 0.7704 - val_loss: 0.5250 - val_accuracy: 0.7598\n",
      "Epoch 188/250\n",
      "514/514 [==============================] - 0s 203us/step - loss: 0.4678 - accuracy: 0.7588 - val_loss: 0.4942 - val_accuracy: 0.7874\n",
      "Epoch 189/250\n",
      "514/514 [==============================] - 0s 246us/step - loss: 0.4749 - accuracy: 0.7763 - val_loss: 0.5263 - val_accuracy: 0.7717\n",
      "Epoch 190/250\n",
      "514/514 [==============================] - 0s 327us/step - loss: 0.4661 - accuracy: 0.7704 - val_loss: 0.5355 - val_accuracy: 0.7756\n",
      "Epoch 191/250\n",
      "514/514 [==============================] - 0s 362us/step - loss: 0.4777 - accuracy: 0.7510 - val_loss: 0.5013 - val_accuracy: 0.7795\n",
      "Epoch 192/250\n",
      "514/514 [==============================] - 0s 220us/step - loss: 0.4683 - accuracy: 0.7646 - val_loss: 0.5082 - val_accuracy: 0.7717\n",
      "Epoch 193/250\n",
      "514/514 [==============================] - 0s 320us/step - loss: 0.4651 - accuracy: 0.7646 - val_loss: 0.5041 - val_accuracy: 0.7795\n",
      "Epoch 194/250\n",
      "514/514 [==============================] - 0s 340us/step - loss: 0.4664 - accuracy: 0.7626 - val_loss: 0.5001 - val_accuracy: 0.7835\n",
      "Epoch 195/250\n",
      "514/514 [==============================] - 0s 219us/step - loss: 0.4637 - accuracy: 0.7704 - val_loss: 0.5097 - val_accuracy: 0.7795\n",
      "Epoch 196/250\n",
      "514/514 [==============================] - 0s 313us/step - loss: 0.4569 - accuracy: 0.7724 - val_loss: 0.5148 - val_accuracy: 0.7677\n",
      "Epoch 197/250\n",
      "514/514 [==============================] - 0s 316us/step - loss: 0.4735 - accuracy: 0.7568 - val_loss: 0.5106 - val_accuracy: 0.7835\n",
      "Epoch 198/250\n",
      "514/514 [==============================] - 0s 224us/step - loss: 0.4559 - accuracy: 0.7665 - val_loss: 0.5029 - val_accuracy: 0.7795\n",
      "Epoch 199/250\n",
      "514/514 [==============================] - 0s 308us/step - loss: 0.4679 - accuracy: 0.7782 - val_loss: 0.5048 - val_accuracy: 0.7835\n",
      "Epoch 200/250\n",
      "514/514 [==============================] - 0s 374us/step - loss: 0.4673 - accuracy: 0.7646 - val_loss: 0.5081 - val_accuracy: 0.7874\n",
      "Epoch 201/250\n",
      "514/514 [==============================] - 0s 318us/step - loss: 0.4600 - accuracy: 0.7763 - val_loss: 0.5013 - val_accuracy: 0.7795\n",
      "Epoch 202/250\n",
      "514/514 [==============================] - 0s 339us/step - loss: 0.4627 - accuracy: 0.7724 - val_loss: 0.5200 - val_accuracy: 0.7717\n",
      "Epoch 203/250\n",
      "514/514 [==============================] - 0s 216us/step - loss: 0.4618 - accuracy: 0.7665 - val_loss: 0.5224 - val_accuracy: 0.7677\n",
      "Epoch 204/250\n",
      "514/514 [==============================] - 0s 310us/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.5327 - val_accuracy: 0.7638\n",
      "Epoch 205/250\n",
      "514/514 [==============================] - 0s 309us/step - loss: 0.4512 - accuracy: 0.7704 - val_loss: 0.5126 - val_accuracy: 0.7717\n",
      "Epoch 206/250\n",
      "514/514 [==============================] - 0s 302us/step - loss: 0.4536 - accuracy: 0.7685 - val_loss: 0.5383 - val_accuracy: 0.7559\n",
      "Epoch 207/250\n",
      "514/514 [==============================] - 0s 347us/step - loss: 0.4728 - accuracy: 0.7568 - val_loss: 0.5311 - val_accuracy: 0.7717\n",
      "Epoch 208/250\n",
      "514/514 [==============================] - 0s 252us/step - loss: 0.4628 - accuracy: 0.7685 - val_loss: 0.5086 - val_accuracy: 0.7756\n",
      "Epoch 209/250\n",
      "514/514 [==============================] - 0s 284us/step - loss: 0.4627 - accuracy: 0.7646 - val_loss: 0.5204 - val_accuracy: 0.7795\n",
      "Epoch 210/250\n",
      "514/514 [==============================] - 0s 244us/step - loss: 0.4594 - accuracy: 0.7782 - val_loss: 0.5177 - val_accuracy: 0.7717\n",
      "Epoch 211/250\n",
      "514/514 [==============================] - 0s 203us/step - loss: 0.4564 - accuracy: 0.7763 - val_loss: 0.5256 - val_accuracy: 0.7717\n",
      "Epoch 212/250\n",
      "514/514 [==============================] - 0s 321us/step - loss: 0.4610 - accuracy: 0.7685 - val_loss: 0.5226 - val_accuracy: 0.7953\n",
      "Epoch 213/250\n",
      "514/514 [==============================] - 0s 364us/step - loss: 0.4736 - accuracy: 0.7451 - val_loss: 0.5259 - val_accuracy: 0.7795\n",
      "Epoch 214/250\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4493 - accuracy: 0.7626 - val_loss: 0.5141 - val_accuracy: 0.7756\n",
      "Epoch 215/250\n",
      "514/514 [==============================] - 0s 239us/step - loss: 0.4629 - accuracy: 0.7665 - val_loss: 0.5255 - val_accuracy: 0.7835\n",
      "Epoch 216/250\n",
      "514/514 [==============================] - 0s 318us/step - loss: 0.4557 - accuracy: 0.7840 - val_loss: 0.5165 - val_accuracy: 0.7795\n",
      "Epoch 217/250\n",
      "514/514 [==============================] - 0s 266us/step - loss: 0.4566 - accuracy: 0.7724 - val_loss: 0.5302 - val_accuracy: 0.7913\n",
      "Epoch 218/250\n",
      "514/514 [==============================] - 0s 326us/step - loss: 0.4562 - accuracy: 0.7646 - val_loss: 0.5209 - val_accuracy: 0.7677\n",
      "Epoch 219/250\n",
      "514/514 [==============================] - 0s 329us/step - loss: 0.4601 - accuracy: 0.7743 - val_loss: 0.5197 - val_accuracy: 0.7756\n",
      "Epoch 220/250\n",
      "514/514 [==============================] - 0s 253us/step - loss: 0.4504 - accuracy: 0.7743 - val_loss: 0.5370 - val_accuracy: 0.7795\n",
      "Epoch 221/250\n",
      "514/514 [==============================] - 0s 316us/step - loss: 0.4543 - accuracy: 0.7763 - val_loss: 0.5343 - val_accuracy: 0.7795\n",
      "Epoch 222/250\n",
      "514/514 [==============================] - 0s 258us/step - loss: 0.4598 - accuracy: 0.7607 - val_loss: 0.5428 - val_accuracy: 0.7756\n",
      "Epoch 223/250\n",
      "514/514 [==============================] - 0s 230us/step - loss: 0.4662 - accuracy: 0.7529 - val_loss: 0.5168 - val_accuracy: 0.7953\n",
      "Epoch 224/250\n",
      "514/514 [==============================] - 0s 309us/step - loss: 0.4586 - accuracy: 0.7646 - val_loss: 0.5125 - val_accuracy: 0.7795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "514/514 [==============================] - 0s 225us/step - loss: 0.4543 - accuracy: 0.7782 - val_loss: 0.5242 - val_accuracy: 0.7913\n",
      "Epoch 226/250\n",
      "514/514 [==============================] - 0s 223us/step - loss: 0.4487 - accuracy: 0.7821 - val_loss: 0.5150 - val_accuracy: 0.7717\n",
      "Epoch 227/250\n",
      "514/514 [==============================] - 0s 342us/step - loss: 0.4583 - accuracy: 0.7802 - val_loss: 0.5202 - val_accuracy: 0.7835\n",
      "Epoch 228/250\n",
      "514/514 [==============================] - 0s 275us/step - loss: 0.4633 - accuracy: 0.7802 - val_loss: 0.5105 - val_accuracy: 0.7874\n",
      "Epoch 229/250\n",
      "514/514 [==============================] - 0s 221us/step - loss: 0.4577 - accuracy: 0.7821 - val_loss: 0.5179 - val_accuracy: 0.7874\n",
      "Epoch 230/250\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.4617 - accuracy: 0.7724 - val_loss: 0.5195 - val_accuracy: 0.7835\n",
      "Epoch 231/250\n",
      "514/514 [==============================] - 0s 115us/step - loss: 0.4456 - accuracy: 0.7802 - val_loss: 0.5143 - val_accuracy: 0.7795\n",
      "Epoch 232/250\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4512 - accuracy: 0.7879 - val_loss: 0.5216 - val_accuracy: 0.7835\n",
      "Epoch 233/250\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.4636 - accuracy: 0.7782 - val_loss: 0.5271 - val_accuracy: 0.7795\n",
      "Epoch 234/250\n",
      "514/514 [==============================] - 0s 167us/step - loss: 0.4573 - accuracy: 0.7665 - val_loss: 0.5104 - val_accuracy: 0.7913\n",
      "Epoch 235/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4643 - accuracy: 0.7821 - val_loss: 0.5285 - val_accuracy: 0.7598\n",
      "Epoch 236/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.4623 - accuracy: 0.7704 - val_loss: 0.5222 - val_accuracy: 0.7756\n",
      "Epoch 237/250\n",
      "514/514 [==============================] - 0s 138us/step - loss: 0.4547 - accuracy: 0.7588 - val_loss: 0.5566 - val_accuracy: 0.7756\n",
      "Epoch 238/250\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.4677 - accuracy: 0.7626 - val_loss: 0.5125 - val_accuracy: 0.7717\n",
      "Epoch 239/250\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4462 - accuracy: 0.7840 - val_loss: 0.5201 - val_accuracy: 0.7795\n",
      "Epoch 240/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.4561 - accuracy: 0.7782 - val_loss: 0.5211 - val_accuracy: 0.7874\n",
      "Epoch 241/250\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.4564 - accuracy: 0.7724 - val_loss: 0.5401 - val_accuracy: 0.7756\n",
      "Epoch 242/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.4559 - accuracy: 0.7763 - val_loss: 0.5213 - val_accuracy: 0.7795\n",
      "Epoch 243/250\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.4599 - accuracy: 0.7626 - val_loss: 0.5235 - val_accuracy: 0.7874\n",
      "Epoch 244/250\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4525 - accuracy: 0.7665 - val_loss: 0.5170 - val_accuracy: 0.7874\n",
      "Epoch 245/250\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.4502 - accuracy: 0.7763 - val_loss: 0.5182 - val_accuracy: 0.7835\n",
      "Epoch 246/250\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4486 - accuracy: 0.7938 - val_loss: 0.5108 - val_accuracy: 0.7874\n",
      "Epoch 247/250\n",
      "514/514 [==============================] - 0s 135us/step - loss: 0.4446 - accuracy: 0.7899 - val_loss: 0.5363 - val_accuracy: 0.7638\n",
      "Epoch 248/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.4494 - accuracy: 0.7782 - val_loss: 0.5343 - val_accuracy: 0.7756\n",
      "Epoch 249/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.4497 - accuracy: 0.7665 - val_loss: 0.5252 - val_accuracy: 0.7756\n",
      "Epoch 250/250\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4479 - accuracy: 0.7821 - val_loss: 0.5340 - val_accuracy: 0.7835\n",
      "768/768 [==============================] - 0s 12us/step\n",
      "accuracy: 77.60%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, Y,validation_split=0.33, epochs=250, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1],scores[1]*100 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/250\n",
      "514/514 [==============================] - 0s 493us/step - loss: 0.6789 - accuracy: 0.6576 - val_loss: 0.6750 - val_accuracy: 0.6378\n",
      "Epoch 2/250\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.6643 - accuracy: 0.6576 - val_loss: 0.6674 - val_accuracy: 0.6378\n",
      "Epoch 3/250\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.6585 - accuracy: 0.6576 - val_loss: 0.6589 - val_accuracy: 0.6378\n",
      "Epoch 4/250\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.6536 - accuracy: 0.6595 - val_loss: 0.6535 - val_accuracy: 0.6378\n",
      "Epoch 5/250\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.6506 - accuracy: 0.6634 - val_loss: 0.6612 - val_accuracy: 0.6378\n",
      "Epoch 6/250\n",
      "514/514 [==============================] - 0s 184us/step - loss: 0.6454 - accuracy: 0.6537 - val_loss: 0.6398 - val_accuracy: 0.6457\n",
      "Epoch 7/250\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.6342 - accuracy: 0.6712 - val_loss: 0.6460 - val_accuracy: 0.6614\n",
      "Epoch 8/250\n",
      "514/514 [==============================] - 0s 235us/step - loss: 0.6263 - accuracy: 0.6751 - val_loss: 0.6268 - val_accuracy: 0.6772\n",
      "Epoch 9/250\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.6168 - accuracy: 0.6712 - val_loss: 0.6161 - val_accuracy: 0.6850\n",
      "Epoch 10/250\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.6074 - accuracy: 0.6965 - val_loss: 0.6344 - val_accuracy: 0.6417\n",
      "Epoch 11/250\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.6021 - accuracy: 0.6965 - val_loss: 0.6007 - val_accuracy: 0.7047\n",
      "Epoch 12/250\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.6008 - accuracy: 0.6907 - val_loss: 0.6006 - val_accuracy: 0.6811\n",
      "Epoch 13/250\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.6002 - accuracy: 0.7043 - val_loss: 0.6179 - val_accuracy: 0.6654\n",
      "Epoch 14/250\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.5869 - accuracy: 0.7043 - val_loss: 0.6105 - val_accuracy: 0.6654\n",
      "Epoch 15/250\n",
      "514/514 [==============================] - 0s 196us/step - loss: 0.5906 - accuracy: 0.6946 - val_loss: 0.5883 - val_accuracy: 0.7165\n",
      "Epoch 16/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.5905 - accuracy: 0.6984 - val_loss: 0.5896 - val_accuracy: 0.6929\n",
      "Epoch 17/250\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.5852 - accuracy: 0.7004 - val_loss: 0.5934 - val_accuracy: 0.6811\n",
      "Epoch 18/250\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.5809 - accuracy: 0.7023 - val_loss: 0.5815 - val_accuracy: 0.7087\n",
      "Epoch 19/250\n",
      "514/514 [==============================] - 0s 219us/step - loss: 0.5787 - accuracy: 0.7160 - val_loss: 0.5806 - val_accuracy: 0.7205\n",
      "Epoch 20/250\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.5786 - accuracy: 0.6868 - val_loss: 0.5774 - val_accuracy: 0.7008\n",
      "Epoch 21/250\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.5738 - accuracy: 0.7062 - val_loss: 0.5769 - val_accuracy: 0.6929\n",
      "Epoch 22/250\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.5722 - accuracy: 0.7198 - val_loss: 0.5747 - val_accuracy: 0.7008\n",
      "Epoch 23/250\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.5740 - accuracy: 0.7023 - val_loss: 0.5806 - val_accuracy: 0.6929\n",
      "Epoch 24/250\n",
      "514/514 [==============================] - 0s 208us/step - loss: 0.5714 - accuracy: 0.7004 - val_loss: 0.5738 - val_accuracy: 0.6929\n",
      "Epoch 25/250\n",
      "514/514 [==============================] - 0s 126us/step - loss: 0.5696 - accuracy: 0.6984 - val_loss: 0.5844 - val_accuracy: 0.7008\n",
      "Epoch 26/250\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5710 - accuracy: 0.7198 - val_loss: 0.5717 - val_accuracy: 0.6890\n",
      "Epoch 27/250\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.5664 - accuracy: 0.7082 - val_loss: 0.5738 - val_accuracy: 0.6969\n",
      "Epoch 28/250\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.5642 - accuracy: 0.7140 - val_loss: 0.5710 - val_accuracy: 0.6969\n",
      "Epoch 29/250\n",
      "514/514 [==============================] - 0s 118us/step - loss: 0.5620 - accuracy: 0.7257 - val_loss: 0.5710 - val_accuracy: 0.7008\n",
      "Epoch 30/250\n",
      "514/514 [==============================] - 0s 119us/step - loss: 0.5713 - accuracy: 0.7062 - val_loss: 0.5764 - val_accuracy: 0.6772\n",
      "Epoch 31/250\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5607 - accuracy: 0.7160 - val_loss: 0.5712 - val_accuracy: 0.7047\n",
      "Epoch 32/250\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.5520 - accuracy: 0.7082 - val_loss: 0.5661 - val_accuracy: 0.6929\n",
      "Epoch 33/250\n",
      "514/514 [==============================] - 0s 228us/step - loss: 0.5539 - accuracy: 0.7393 - val_loss: 0.5736 - val_accuracy: 0.7126\n",
      "Epoch 34/250\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.5555 - accuracy: 0.7179 - val_loss: 0.5653 - val_accuracy: 0.7008\n",
      "Epoch 35/250\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.5524 - accuracy: 0.7315 - val_loss: 0.5647 - val_accuracy: 0.7047\n",
      "Epoch 36/250\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.5482 - accuracy: 0.7315 - val_loss: 0.5684 - val_accuracy: 0.7165\n",
      "Epoch 37/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.5475 - accuracy: 0.7237 - val_loss: 0.5669 - val_accuracy: 0.7047\n",
      "Epoch 38/250\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.5523 - accuracy: 0.7140 - val_loss: 0.5616 - val_accuracy: 0.7047\n",
      "Epoch 39/250\n",
      "514/514 [==============================] - 0s 142us/step - loss: 0.5464 - accuracy: 0.7257 - val_loss: 0.5609 - val_accuracy: 0.6969\n",
      "Epoch 40/250\n",
      "514/514 [==============================] - 0s 139us/step - loss: 0.5482 - accuracy: 0.7432 - val_loss: 0.5609 - val_accuracy: 0.7205\n",
      "Epoch 41/250\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.5438 - accuracy: 0.7276 - val_loss: 0.5690 - val_accuracy: 0.7165\n",
      "Epoch 42/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.5450 - accuracy: 0.7218 - val_loss: 0.5664 - val_accuracy: 0.7244\n",
      "Epoch 43/250\n",
      "514/514 [==============================] - 0s 125us/step - loss: 0.5456 - accuracy: 0.7432 - val_loss: 0.5785 - val_accuracy: 0.6811\n",
      "Epoch 44/250\n",
      "514/514 [==============================] - 0s 83us/step - loss: 0.5549 - accuracy: 0.7276 - val_loss: 0.5574 - val_accuracy: 0.7165\n",
      "Epoch 45/250\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5425 - accuracy: 0.7432 - val_loss: 0.5739 - val_accuracy: 0.7323\n",
      "Epoch 46/250\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.5352 - accuracy: 0.7393 - val_loss: 0.5598 - val_accuracy: 0.7244\n",
      "Epoch 47/250\n",
      "514/514 [==============================] - 0s 285us/step - loss: 0.5393 - accuracy: 0.7432 - val_loss: 0.5904 - val_accuracy: 0.7087\n",
      "Epoch 48/250\n",
      "514/514 [==============================] - 0s 276us/step - loss: 0.5409 - accuracy: 0.7315 - val_loss: 0.5612 - val_accuracy: 0.7087\n",
      "Epoch 49/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.5344 - accuracy: 0.7393 - val_loss: 0.5535 - val_accuracy: 0.7165\n",
      "Epoch 50/250\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5310 - accuracy: 0.7451 - val_loss: 0.5688 - val_accuracy: 0.7126\n",
      "Epoch 51/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.5306 - accuracy: 0.7393 - val_loss: 0.5512 - val_accuracy: 0.7244\n",
      "Epoch 52/250\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.5262 - accuracy: 0.7393 - val_loss: 0.5584 - val_accuracy: 0.7283\n",
      "Epoch 53/250\n",
      "514/514 [==============================] - 0s 195us/step - loss: 0.5326 - accuracy: 0.7529 - val_loss: 0.5464 - val_accuracy: 0.7205\n",
      "Epoch 54/250\n",
      "514/514 [==============================] - 0s 176us/step - loss: 0.5502 - accuracy: 0.7335 - val_loss: 0.5688 - val_accuracy: 0.7047\n",
      "Epoch 55/250\n",
      "514/514 [==============================] - 0s 146us/step - loss: 0.5336 - accuracy: 0.7374 - val_loss: 0.5487 - val_accuracy: 0.7205\n",
      "Epoch 56/250\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.5320 - accuracy: 0.7374 - val_loss: 0.5578 - val_accuracy: 0.7205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/250\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.5329 - accuracy: 0.7218 - val_loss: 0.5649 - val_accuracy: 0.7087\n",
      "Epoch 58/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.5189 - accuracy: 0.7549 - val_loss: 0.5387 - val_accuracy: 0.7323\n",
      "Epoch 59/250\n",
      "514/514 [==============================] - 0s 133us/step - loss: 0.5202 - accuracy: 0.7510 - val_loss: 0.5434 - val_accuracy: 0.7244\n",
      "Epoch 60/250\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.5220 - accuracy: 0.7529 - val_loss: 0.5575 - val_accuracy: 0.7283\n",
      "Epoch 61/250\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.5204 - accuracy: 0.7315 - val_loss: 0.5418 - val_accuracy: 0.7244\n",
      "Epoch 62/250\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.5129 - accuracy: 0.7549 - val_loss: 0.5495 - val_accuracy: 0.7126\n",
      "Epoch 63/250\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.5270 - accuracy: 0.7568 - val_loss: 0.5310 - val_accuracy: 0.7323\n",
      "Epoch 64/250\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.5144 - accuracy: 0.7432 - val_loss: 0.5419 - val_accuracy: 0.7283\n",
      "Epoch 65/250\n",
      "514/514 [==============================] - 0s 132us/step - loss: 0.5102 - accuracy: 0.7588 - val_loss: 0.5443 - val_accuracy: 0.7402\n",
      "Epoch 66/250\n",
      "514/514 [==============================] - 0s 126us/step - loss: 0.5311 - accuracy: 0.7412 - val_loss: 0.5362 - val_accuracy: 0.7244\n",
      "Epoch 67/250\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5113 - accuracy: 0.7490 - val_loss: 0.5324 - val_accuracy: 0.7441\n",
      "Epoch 68/250\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.5078 - accuracy: 0.7471 - val_loss: 0.5319 - val_accuracy: 0.7441\n",
      "Epoch 69/250\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5071 - accuracy: 0.7510 - val_loss: 0.5371 - val_accuracy: 0.7441\n",
      "Epoch 70/250\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5079 - accuracy: 0.7607 - val_loss: 0.5301 - val_accuracy: 0.7323\n",
      "Epoch 71/250\n",
      "514/514 [==============================] - 0s 126us/step - loss: 0.4971 - accuracy: 0.7724 - val_loss: 0.5281 - val_accuracy: 0.7323\n",
      "Epoch 72/250\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5084 - accuracy: 0.7393 - val_loss: 0.5312 - val_accuracy: 0.7323\n",
      "Epoch 73/250\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4988 - accuracy: 0.7763 - val_loss: 0.5293 - val_accuracy: 0.7441\n",
      "Epoch 74/250\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.4956 - accuracy: 0.7685 - val_loss: 0.5392 - val_accuracy: 0.7165\n",
      "Epoch 75/250\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.5040 - accuracy: 0.7665 - val_loss: 0.5400 - val_accuracy: 0.7362\n",
      "Epoch 76/250\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.4976 - accuracy: 0.7646 - val_loss: 0.5406 - val_accuracy: 0.7402\n",
      "Epoch 77/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4989 - accuracy: 0.7588 - val_loss: 0.5266 - val_accuracy: 0.7323\n",
      "Epoch 78/250\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.5016 - accuracy: 0.7451 - val_loss: 0.5236 - val_accuracy: 0.7480\n",
      "Epoch 79/250\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4936 - accuracy: 0.7665 - val_loss: 0.5301 - val_accuracy: 0.7323\n",
      "Epoch 80/250\n",
      "514/514 [==============================] - 0s 119us/step - loss: 0.4921 - accuracy: 0.7724 - val_loss: 0.5326 - val_accuracy: 0.7480\n",
      "Epoch 81/250\n",
      "514/514 [==============================] - 0s 81us/step - loss: 0.4908 - accuracy: 0.7821 - val_loss: 0.5202 - val_accuracy: 0.7598\n",
      "Epoch 82/250\n",
      "514/514 [==============================] - 0s 127us/step - loss: 0.4975 - accuracy: 0.7549 - val_loss: 0.5260 - val_accuracy: 0.7480\n",
      "Epoch 83/250\n",
      "514/514 [==============================] - 0s 130us/step - loss: 0.5031 - accuracy: 0.7626 - val_loss: 0.5297 - val_accuracy: 0.7283\n",
      "Epoch 84/250\n",
      "514/514 [==============================] - 0s 112us/step - loss: 0.5015 - accuracy: 0.7588 - val_loss: 0.5452 - val_accuracy: 0.7323\n",
      "Epoch 85/250\n",
      "514/514 [==============================] - 0s 85us/step - loss: 0.4941 - accuracy: 0.7704 - val_loss: 0.5207 - val_accuracy: 0.7323\n",
      "Epoch 86/250\n",
      "514/514 [==============================] - 0s 130us/step - loss: 0.4869 - accuracy: 0.7724 - val_loss: 0.5345 - val_accuracy: 0.7244\n",
      "Epoch 87/250\n",
      "514/514 [==============================] - 0s 307us/step - loss: 0.4845 - accuracy: 0.7685 - val_loss: 0.5209 - val_accuracy: 0.7480\n",
      "Epoch 88/250\n",
      "514/514 [==============================] - 0s 286us/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.5220 - val_accuracy: 0.7441\n",
      "Epoch 89/250\n",
      "514/514 [==============================] - 0s 300us/step - loss: 0.4817 - accuracy: 0.7743 - val_loss: 0.5375 - val_accuracy: 0.7283\n",
      "Epoch 90/250\n",
      "514/514 [==============================] - 0s 272us/step - loss: 0.4839 - accuracy: 0.7724 - val_loss: 0.5250 - val_accuracy: 0.7283\n",
      "Epoch 91/250\n",
      "514/514 [==============================] - 0s 341us/step - loss: 0.4819 - accuracy: 0.7918 - val_loss: 0.5205 - val_accuracy: 0.7362\n",
      "Epoch 92/250\n",
      "514/514 [==============================] - 0s 293us/step - loss: 0.4775 - accuracy: 0.7918 - val_loss: 0.5229 - val_accuracy: 0.7559\n",
      "Epoch 93/250\n",
      "514/514 [==============================] - 0s 254us/step - loss: 0.4861 - accuracy: 0.7782 - val_loss: 0.5508 - val_accuracy: 0.7283\n",
      "Epoch 94/250\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.4817 - accuracy: 0.7724 - val_loss: 0.5211 - val_accuracy: 0.7559\n",
      "Epoch 95/250\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4769 - accuracy: 0.7782 - val_loss: 0.5197 - val_accuracy: 0.7205\n",
      "Epoch 96/250\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4846 - accuracy: 0.7665 - val_loss: 0.5270 - val_accuracy: 0.7323\n",
      "Epoch 97/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4757 - accuracy: 0.7802 - val_loss: 0.5173 - val_accuracy: 0.7520\n",
      "Epoch 98/250\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4744 - accuracy: 0.7840 - val_loss: 0.5261 - val_accuracy: 0.7598\n",
      "Epoch 99/250\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.4828 - accuracy: 0.7588 - val_loss: 0.5717 - val_accuracy: 0.7126\n",
      "Epoch 100/250\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4812 - accuracy: 0.7821 - val_loss: 0.5230 - val_accuracy: 0.7205\n",
      "Epoch 101/250\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.4807 - accuracy: 0.7646 - val_loss: 0.5177 - val_accuracy: 0.7559\n",
      "Epoch 102/250\n",
      "514/514 [==============================] - 0s 126us/step - loss: 0.4825 - accuracy: 0.7665 - val_loss: 0.5225 - val_accuracy: 0.7677\n",
      "Epoch 103/250\n",
      "514/514 [==============================] - 0s 170us/step - loss: 0.4721 - accuracy: 0.7879 - val_loss: 0.5226 - val_accuracy: 0.7480\n",
      "Epoch 104/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.4769 - accuracy: 0.7626 - val_loss: 0.5181 - val_accuracy: 0.7677\n",
      "Epoch 105/250\n",
      "514/514 [==============================] - 0s 192us/step - loss: 0.4679 - accuracy: 0.7665 - val_loss: 0.5368 - val_accuracy: 0.7402\n",
      "Epoch 106/250\n",
      "514/514 [==============================] - 0s 175us/step - loss: 0.4733 - accuracy: 0.7724 - val_loss: 0.5300 - val_accuracy: 0.7402\n",
      "Epoch 107/250\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4771 - accuracy: 0.7665 - val_loss: 0.5303 - val_accuracy: 0.7244\n",
      "Epoch 108/250\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.5370 - val_accuracy: 0.7441\n",
      "Epoch 109/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.4761 - accuracy: 0.7879 - val_loss: 0.5240 - val_accuracy: 0.7441\n",
      "Epoch 110/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.4755 - accuracy: 0.7802 - val_loss: 0.5270 - val_accuracy: 0.7441\n",
      "Epoch 111/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.4638 - accuracy: 0.7957 - val_loss: 0.5262 - val_accuracy: 0.7205\n",
      "Epoch 112/250\n",
      "514/514 [==============================] - 0s 178us/step - loss: 0.4688 - accuracy: 0.7840 - val_loss: 0.5200 - val_accuracy: 0.7520\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 142us/step - loss: 0.4643 - accuracy: 0.7996 - val_loss: 0.5187 - val_accuracy: 0.7559\n",
      "Epoch 114/250\n",
      "514/514 [==============================] - 0s 115us/step - loss: 0.4735 - accuracy: 0.7821 - val_loss: 0.5249 - val_accuracy: 0.7480\n",
      "Epoch 115/250\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.4643 - accuracy: 0.7840 - val_loss: 0.5166 - val_accuracy: 0.7480\n",
      "Epoch 116/250\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4721 - accuracy: 0.7802 - val_loss: 0.5181 - val_accuracy: 0.7520\n",
      "Epoch 117/250\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4656 - accuracy: 0.7821 - val_loss: 0.5167 - val_accuracy: 0.7480\n",
      "Epoch 118/250\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.4699 - accuracy: 0.7665 - val_loss: 0.5172 - val_accuracy: 0.7638\n",
      "Epoch 119/250\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.5191 - val_accuracy: 0.7598\n",
      "Epoch 120/250\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.4588 - accuracy: 0.7899 - val_loss: 0.5144 - val_accuracy: 0.7598\n",
      "Epoch 121/250\n",
      "514/514 [==============================] - 0s 93us/step - loss: 0.4683 - accuracy: 0.7782 - val_loss: 0.5309 - val_accuracy: 0.7520\n",
      "Epoch 122/250\n",
      "514/514 [==============================] - 0s 127us/step - loss: 0.4637 - accuracy: 0.7879 - val_loss: 0.5316 - val_accuracy: 0.7283\n",
      "Epoch 123/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.4605 - accuracy: 0.7977 - val_loss: 0.5124 - val_accuracy: 0.7598\n",
      "Epoch 124/250\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.4567 - accuracy: 0.7879 - val_loss: 0.5128 - val_accuracy: 0.7677\n",
      "Epoch 125/250\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4653 - accuracy: 0.7802 - val_loss: 0.5216 - val_accuracy: 0.7323\n",
      "Epoch 126/250\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4590 - accuracy: 0.8016 - val_loss: 0.5171 - val_accuracy: 0.7480\n",
      "Epoch 127/250\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.4584 - accuracy: 0.7918 - val_loss: 0.5159 - val_accuracy: 0.7598\n",
      "Epoch 128/250\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.4547 - accuracy: 0.7918 - val_loss: 0.5255 - val_accuracy: 0.7362\n",
      "Epoch 129/250\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4517 - accuracy: 0.7899 - val_loss: 0.5193 - val_accuracy: 0.7598\n",
      "Epoch 130/250\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.4576 - accuracy: 0.7938 - val_loss: 0.5152 - val_accuracy: 0.7598\n",
      "Epoch 131/250\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4537 - accuracy: 0.7840 - val_loss: 0.5126 - val_accuracy: 0.7441\n",
      "Epoch 132/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4572 - accuracy: 0.7879 - val_loss: 0.5461 - val_accuracy: 0.7283\n",
      "Epoch 133/250\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.4602 - accuracy: 0.8016 - val_loss: 0.5140 - val_accuracy: 0.7480\n",
      "Epoch 134/250\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4555 - accuracy: 0.7821 - val_loss: 0.5137 - val_accuracy: 0.7559\n",
      "Epoch 135/250\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.4484 - accuracy: 0.7860 - val_loss: 0.5425 - val_accuracy: 0.7362\n",
      "Epoch 136/250\n",
      "514/514 [==============================] - 0s 115us/step - loss: 0.4606 - accuracy: 0.7977 - val_loss: 0.5301 - val_accuracy: 0.7323\n",
      "Epoch 137/250\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4597 - accuracy: 0.7918 - val_loss: 0.5177 - val_accuracy: 0.7480\n",
      "Epoch 138/250\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.4536 - accuracy: 0.7977 - val_loss: 0.5144 - val_accuracy: 0.7520\n",
      "Epoch 139/250\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4512 - accuracy: 0.7957 - val_loss: 0.5202 - val_accuracy: 0.7598\n",
      "Epoch 140/250\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.4515 - accuracy: 0.7802 - val_loss: 0.5180 - val_accuracy: 0.7598\n",
      "Epoch 141/250\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.4473 - accuracy: 0.7977 - val_loss: 0.5110 - val_accuracy: 0.7598\n",
      "Epoch 142/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4612 - accuracy: 0.7665 - val_loss: 0.5327 - val_accuracy: 0.7323\n",
      "Epoch 143/250\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.5167 - val_accuracy: 0.7441\n",
      "Epoch 144/250\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4420 - accuracy: 0.7918 - val_loss: 0.5256 - val_accuracy: 0.7638\n",
      "Epoch 145/250\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.4409 - accuracy: 0.7996 - val_loss: 0.5307 - val_accuracy: 0.7323\n",
      "Epoch 146/250\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.4448 - accuracy: 0.7860 - val_loss: 0.5176 - val_accuracy: 0.7480\n",
      "Epoch 147/250\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.4448 - accuracy: 0.7840 - val_loss: 0.5197 - val_accuracy: 0.7520\n",
      "Epoch 148/250\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.4427 - accuracy: 0.7918 - val_loss: 0.5187 - val_accuracy: 0.7441\n",
      "Epoch 149/250\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.4462 - accuracy: 0.7918 - val_loss: 0.5168 - val_accuracy: 0.7559\n",
      "Epoch 150/250\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.5316 - val_accuracy: 0.7559\n",
      "Epoch 151/250\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4518 - accuracy: 0.8113 - val_loss: 0.5172 - val_accuracy: 0.7441\n",
      "Epoch 152/250\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4421 - accuracy: 0.7782 - val_loss: 0.5268 - val_accuracy: 0.7677\n",
      "Epoch 153/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4377 - accuracy: 0.7938 - val_loss: 0.5215 - val_accuracy: 0.7638\n",
      "Epoch 154/250\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.4442 - accuracy: 0.7840 - val_loss: 0.5237 - val_accuracy: 0.7717\n",
      "Epoch 155/250\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.4448 - accuracy: 0.7957 - val_loss: 0.5222 - val_accuracy: 0.7520\n",
      "Epoch 156/250\n",
      "514/514 [==============================] - 0s 244us/step - loss: 0.4447 - accuracy: 0.7957 - val_loss: 0.5185 - val_accuracy: 0.7559\n",
      "Epoch 157/250\n",
      "514/514 [==============================] - 0s 222us/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5180 - val_accuracy: 0.7441\n",
      "Epoch 158/250\n",
      "514/514 [==============================] - 0s 235us/step - loss: 0.4452 - accuracy: 0.8016 - val_loss: 0.5165 - val_accuracy: 0.7441\n",
      "Epoch 159/250\n",
      "514/514 [==============================] - 0s 218us/step - loss: 0.4456 - accuracy: 0.7938 - val_loss: 0.5254 - val_accuracy: 0.7480\n",
      "Epoch 160/250\n",
      "514/514 [==============================] - 0s 227us/step - loss: 0.4398 - accuracy: 0.7977 - val_loss: 0.5206 - val_accuracy: 0.7559\n",
      "Epoch 161/250\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.4335 - accuracy: 0.8093 - val_loss: 0.5133 - val_accuracy: 0.7402\n",
      "Epoch 162/250\n",
      "514/514 [==============================] - 0s 170us/step - loss: 0.4322 - accuracy: 0.7957 - val_loss: 0.5426 - val_accuracy: 0.7362\n",
      "Epoch 163/250\n",
      "514/514 [==============================] - 0s 139us/step - loss: 0.4508 - accuracy: 0.7938 - val_loss: 0.5194 - val_accuracy: 0.7520\n",
      "Epoch 164/250\n",
      "514/514 [==============================] - 0s 130us/step - loss: 0.4361 - accuracy: 0.8074 - val_loss: 0.5607 - val_accuracy: 0.7323\n",
      "Epoch 165/250\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.4390 - accuracy: 0.8016 - val_loss: 0.5536 - val_accuracy: 0.7362\n",
      "Epoch 166/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.4440 - accuracy: 0.8113 - val_loss: 0.5360 - val_accuracy: 0.7362\n",
      "Epoch 167/250\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.4349 - accuracy: 0.7821 - val_loss: 0.5471 - val_accuracy: 0.7638\n",
      "Epoch 168/250\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.4370 - accuracy: 0.7977 - val_loss: 0.5185 - val_accuracy: 0.7441\n",
      "Epoch 169/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 150us/step - loss: 0.4351 - accuracy: 0.8016 - val_loss: 0.5310 - val_accuracy: 0.7362\n",
      "Epoch 170/250\n",
      "514/514 [==============================] - 0s 131us/step - loss: 0.4316 - accuracy: 0.8093 - val_loss: 0.5283 - val_accuracy: 0.7717\n",
      "Epoch 171/250\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.4355 - accuracy: 0.8035 - val_loss: 0.5211 - val_accuracy: 0.7520\n",
      "Epoch 172/250\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.4400 - accuracy: 0.8016 - val_loss: 0.5344 - val_accuracy: 0.7480\n",
      "Epoch 173/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.4267 - accuracy: 0.8074 - val_loss: 0.5150 - val_accuracy: 0.7559\n",
      "Epoch 174/250\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.4371 - accuracy: 0.7938 - val_loss: 0.5173 - val_accuracy: 0.7520\n",
      "Epoch 175/250\n",
      "514/514 [==============================] - 0s 135us/step - loss: 0.4305 - accuracy: 0.7938 - val_loss: 0.5274 - val_accuracy: 0.7323\n",
      "Epoch 176/250\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.4371 - accuracy: 0.7918 - val_loss: 0.5258 - val_accuracy: 0.7638\n",
      "Epoch 177/250\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4405 - accuracy: 0.7938 - val_loss: 0.5483 - val_accuracy: 0.7323\n",
      "Epoch 178/250\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4306 - accuracy: 0.7996 - val_loss: 0.5262 - val_accuracy: 0.7520\n",
      "Epoch 179/250\n",
      "514/514 [==============================] - 0s 130us/step - loss: 0.4368 - accuracy: 0.7977 - val_loss: 0.5253 - val_accuracy: 0.7441\n",
      "Epoch 180/250\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5254 - val_accuracy: 0.7638\n",
      "Epoch 181/250\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.4259 - accuracy: 0.8074 - val_loss: 0.5261 - val_accuracy: 0.7677\n",
      "Epoch 182/250\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4242 - accuracy: 0.8093 - val_loss: 0.5222 - val_accuracy: 0.7677\n",
      "Epoch 183/250\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4459 - accuracy: 0.7918 - val_loss: 0.5265 - val_accuracy: 0.7402\n",
      "Epoch 184/250\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4323 - accuracy: 0.8132 - val_loss: 0.5542 - val_accuracy: 0.7480\n",
      "Epoch 185/250\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4308 - accuracy: 0.8016 - val_loss: 0.5379 - val_accuracy: 0.7402\n",
      "Epoch 186/250\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5172 - val_accuracy: 0.7480\n",
      "Epoch 187/250\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4280 - accuracy: 0.8054 - val_loss: 0.5186 - val_accuracy: 0.7559\n",
      "Epoch 188/250\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.4242 - accuracy: 0.8035 - val_loss: 0.5249 - val_accuracy: 0.7480\n",
      "Epoch 189/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4276 - accuracy: 0.8171 - val_loss: 0.5303 - val_accuracy: 0.7520\n",
      "Epoch 190/250\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4281 - accuracy: 0.7938 - val_loss: 0.5401 - val_accuracy: 0.7441\n",
      "Epoch 191/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.4265 - accuracy: 0.7802 - val_loss: 0.5597 - val_accuracy: 0.7402\n",
      "Epoch 192/250\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4435 - accuracy: 0.7840 - val_loss: 0.5242 - val_accuracy: 0.7480\n",
      "Epoch 193/250\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4305 - accuracy: 0.7821 - val_loss: 0.5294 - val_accuracy: 0.7717\n",
      "Epoch 194/250\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.4216 - accuracy: 0.8171 - val_loss: 0.5204 - val_accuracy: 0.7520\n",
      "Epoch 195/250\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.4286 - accuracy: 0.8016 - val_loss: 0.5193 - val_accuracy: 0.7559\n",
      "Epoch 196/250\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.4243 - accuracy: 0.7938 - val_loss: 0.5167 - val_accuracy: 0.7598\n",
      "Epoch 197/250\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.4331 - accuracy: 0.7977 - val_loss: 0.5345 - val_accuracy: 0.7638\n",
      "Epoch 198/250\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4426 - accuracy: 0.7957 - val_loss: 0.5363 - val_accuracy: 0.7480\n",
      "Epoch 199/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.4385 - accuracy: 0.7860 - val_loss: 0.5237 - val_accuracy: 0.7598\n",
      "Epoch 200/250\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.4216 - accuracy: 0.8132 - val_loss: 0.5298 - val_accuracy: 0.7441\n",
      "Epoch 201/250\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.4256 - accuracy: 0.7879 - val_loss: 0.5349 - val_accuracy: 0.7717\n",
      "Epoch 202/250\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.4341 - accuracy: 0.7996 - val_loss: 0.5232 - val_accuracy: 0.7756\n",
      "Epoch 203/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.4230 - accuracy: 0.8016 - val_loss: 0.5244 - val_accuracy: 0.7559\n",
      "Epoch 204/250\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4297 - accuracy: 0.7782 - val_loss: 0.5161 - val_accuracy: 0.7598\n",
      "Epoch 205/250\n",
      "514/514 [==============================] - 0s 130us/step - loss: 0.4291 - accuracy: 0.7957 - val_loss: 0.5226 - val_accuracy: 0.7441\n",
      "Epoch 206/250\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.4242 - accuracy: 0.8113 - val_loss: 0.5279 - val_accuracy: 0.7677\n",
      "Epoch 207/250\n",
      "514/514 [==============================] - 0s 93us/step - loss: 0.4192 - accuracy: 0.7957 - val_loss: 0.5531 - val_accuracy: 0.7441\n",
      "Epoch 208/250\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.4218 - accuracy: 0.7957 - val_loss: 0.5213 - val_accuracy: 0.7441\n",
      "Epoch 209/250\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.4147 - accuracy: 0.8210 - val_loss: 0.5328 - val_accuracy: 0.7480\n",
      "Epoch 210/250\n",
      "514/514 [==============================] - 0s 84us/step - loss: 0.4326 - accuracy: 0.7977 - val_loss: 0.5228 - val_accuracy: 0.7402\n",
      "Epoch 211/250\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.4357 - accuracy: 0.8016 - val_loss: 0.5213 - val_accuracy: 0.7480\n",
      "Epoch 212/250\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.4307 - accuracy: 0.7938 - val_loss: 0.5316 - val_accuracy: 0.7323\n",
      "Epoch 213/250\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.4124 - accuracy: 0.8249 - val_loss: 0.5241 - val_accuracy: 0.7520\n",
      "Epoch 214/250\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.4152 - accuracy: 0.8093 - val_loss: 0.5436 - val_accuracy: 0.7677\n",
      "Epoch 215/250\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.4315 - accuracy: 0.7879 - val_loss: 0.5600 - val_accuracy: 0.7402\n",
      "Epoch 216/250\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4273 - accuracy: 0.8074 - val_loss: 0.5198 - val_accuracy: 0.7638\n",
      "Epoch 217/250\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.4186 - accuracy: 0.7996 - val_loss: 0.5309 - val_accuracy: 0.7520\n",
      "Epoch 218/250\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.4178 - accuracy: 0.7860 - val_loss: 0.5334 - val_accuracy: 0.7598\n",
      "Epoch 219/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4191 - accuracy: 0.8016 - val_loss: 0.5342 - val_accuracy: 0.7480\n",
      "Epoch 220/250\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4278 - accuracy: 0.7957 - val_loss: 0.5408 - val_accuracy: 0.7441\n",
      "Epoch 221/250\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5432 - val_accuracy: 0.7559\n",
      "Epoch 222/250\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.4212 - accuracy: 0.7996 - val_loss: 0.5241 - val_accuracy: 0.7598\n",
      "Epoch 223/250\n",
      "514/514 [==============================] - 0s 125us/step - loss: 0.4231 - accuracy: 0.7918 - val_loss: 0.5321 - val_accuracy: 0.7480\n",
      "Epoch 224/250\n",
      "514/514 [==============================] - 0s 121us/step - loss: 0.4220 - accuracy: 0.7957 - val_loss: 0.5536 - val_accuracy: 0.7480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.4242 - accuracy: 0.7918 - val_loss: 0.5195 - val_accuracy: 0.7441\n",
      "Epoch 226/250\n",
      "514/514 [==============================] - 0s 112us/step - loss: 0.4295 - accuracy: 0.7860 - val_loss: 0.5244 - val_accuracy: 0.7441\n",
      "Epoch 227/250\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4231 - accuracy: 0.7996 - val_loss: 0.5412 - val_accuracy: 0.7402\n",
      "Epoch 228/250\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.4126 - accuracy: 0.7996 - val_loss: 0.5315 - val_accuracy: 0.7756\n",
      "Epoch 229/250\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.4089 - accuracy: 0.8016 - val_loss: 0.5413 - val_accuracy: 0.7677\n",
      "Epoch 230/250\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.4163 - accuracy: 0.8093 - val_loss: 0.5271 - val_accuracy: 0.7520\n",
      "Epoch 231/250\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4136 - accuracy: 0.8113 - val_loss: 0.5353 - val_accuracy: 0.7480\n",
      "Epoch 232/250\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4134 - accuracy: 0.8093 - val_loss: 0.5390 - val_accuracy: 0.7402\n",
      "Epoch 233/250\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.4101 - accuracy: 0.7957 - val_loss: 0.5437 - val_accuracy: 0.7717\n",
      "Epoch 234/250\n",
      "514/514 [==============================] - 0s 193us/step - loss: 0.4095 - accuracy: 0.8035 - val_loss: 0.5277 - val_accuracy: 0.7598\n",
      "Epoch 235/250\n",
      "514/514 [==============================] - 0s 170us/step - loss: 0.4137 - accuracy: 0.7996 - val_loss: 0.5222 - val_accuracy: 0.7480\n",
      "Epoch 236/250\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5380 - val_accuracy: 0.7677\n",
      "Epoch 237/250\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.4050 - accuracy: 0.8035 - val_loss: 0.5442 - val_accuracy: 0.7283\n",
      "Epoch 238/250\n",
      "514/514 [==============================] - 0s 126us/step - loss: 0.4189 - accuracy: 0.7977 - val_loss: 0.5318 - val_accuracy: 0.7520\n",
      "Epoch 239/250\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.4137 - accuracy: 0.8152 - val_loss: 0.5409 - val_accuracy: 0.7402\n",
      "Epoch 240/250\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.4284 - accuracy: 0.7977 - val_loss: 0.5472 - val_accuracy: 0.7795\n",
      "Epoch 241/250\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.4101 - accuracy: 0.8016 - val_loss: 0.5527 - val_accuracy: 0.7323\n",
      "Epoch 242/250\n",
      "514/514 [==============================] - 0s 118us/step - loss: 0.4309 - accuracy: 0.7977 - val_loss: 0.5213 - val_accuracy: 0.7677\n",
      "Epoch 243/250\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4028 - accuracy: 0.7957 - val_loss: 0.5417 - val_accuracy: 0.7520\n",
      "Epoch 244/250\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4150 - accuracy: 0.8074 - val_loss: 0.5272 - val_accuracy: 0.7638\n",
      "Epoch 245/250\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.4180 - accuracy: 0.8074 - val_loss: 0.5385 - val_accuracy: 0.7559\n",
      "Epoch 246/250\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.4187 - accuracy: 0.7977 - val_loss: 0.5230 - val_accuracy: 0.7402\n",
      "Epoch 247/250\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.4187 - accuracy: 0.8074 - val_loss: 0.5366 - val_accuracy: 0.7598\n",
      "Epoch 248/250\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.4126 - accuracy: 0.7938 - val_loss: 0.5254 - val_accuracy: 0.7520\n",
      "Epoch 249/250\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.4138 - accuracy: 0.7957 - val_loss: 0.5349 - val_accuracy: 0.7520\n",
      "Epoch 250/250\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4139 - accuracy: 0.8093 - val_loss: 0.5311 - val_accuracy: 0.7441\n",
      "768/768 [==============================] - 0s 19us/step\n",
      "accuracy: 77.73%\n"
     ]
    }
   ],
   "source": [
    "# verfication using manual split#from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8] \n",
    "\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=250, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1],scores[1]*100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.32%\n",
      "accuracy: 71.43%\n",
      "accuracy: 76.62%\n",
      "accuracy: 77.92%\n",
      "accuracy: 76.62%\n",
      "accuracy: 74.03%\n",
      "accuracy: 76.62%\n",
      "accuracy: 70.13%\n",
      "accuracy: 73.68%\n",
      "accuracy: 77.63%\n",
      "75.00% (+/- 2.50%)\n"
     ]
    }
   ],
   "source": [
    "# Manual K-fold cross validation \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print('%s: %.2f%%' % (model.metrics_names[1],scores[1]*100 ) )\n",
    "    cvscores.append(scores[1]*100)\n",
    "print('%.2f%% (+/- %.2f%%)' % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7447539210319519\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "#fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "#create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "#evaluate usinf 10-fold cross validation \n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search deep learning model parameters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in minutes: 289.745488746961\n",
      "Best: 0.752604 using {'batch_size': 5, 'epochs': 150, 'kernel_initializer': 'uniform', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3a478e9812af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Print the parameters and their results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_results' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(kernel_initializer='uniform', optimizer='adam'):\n",
    "    #create mode\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer=kernel_initializer, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load data\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "#create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epoch = np.array([50, 100, 150])\n",
    "batches = np.array([5, 10, 20])\n",
    "param_grid = dict(optimizer=optimizers, epochs=epoch, batch_size=batches, kernel_initializer=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken in minutes: %s' %((end-start)/60))\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#for params, mean_score, scores in grid_result.cv_results_:\n",
    "    #print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "    \n",
    "# Print the parameters and their results\n",
    "for i in ['mean_test_score', 'std_test_score', 'params']:\n",
    "    print(i,\" : \",grid_results.cv_results_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
